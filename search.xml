<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Code Fragment</title>
    <url>/2021/09/28/Code-Fragment/</url>
    <content><![CDATA[<h1 id="代码片段"><a href="#代码片段" class="headerlink" title="代码片段"></a>代码片段</h1><blockquote>
<p>为方便coding，打算把一些固定的，便携的代码收录下来方便以后直接拿来吧你</p>
</blockquote>
<span id="more"></span>
<ul>
<li>获取目录下的所有（指定名称或格式）文件</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">files_A = <span class="built_in">sorted</span>(glob.glob(os.path.join(rootA, <span class="string">&#x27;*.*&#x27;</span>)))</span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/GeorgeAI/article/details/81035422">glob.glob()的用法</a></p>
<ul>
<li>新建文件夹，若存在，则全部删除</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">file_create</span>(<span class="params">filename</span>):</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(filename):</span><br><span class="line">        print(<span class="string">&#x27;found exist file and remove it&#x27;</span>)</span><br><span class="line">        shutil.rmtree(filename)</span><br><span class="line">        os.mkdir(filename)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        os.mkdir(filename)</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>Cpp_Firstclass</title>
    <url>/2021/10/21/Cpp-Firstclass/</url>
    <content><![CDATA[<h1 id="Cpp第一个Cpp程序"><a href="#Cpp第一个Cpp程序" class="headerlink" title="Cpp第一个Cpp程序"></a>Cpp第一个Cpp程序</h1><span id="more"></span>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostrem&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;Hello, World I am&quot;</span> &lt;&lt; <span class="number">18</span> &lt;&lt; <span class="string">&quot;Today!&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="读输入"><a href="#读输入" class="headerlink" title="读输入"></a>读输入</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> number;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;Enter a demical number: &quot;</span>;</span><br><span class="line">	<span class="built_in">cin</span> &gt;&gt; number;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;The number you entered is &quot;</span> &lt;&lt; number &lt;&lt; <span class="string">&quot;.&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>Cpp</tag>
      </tags>
  </entry>
  <entry>
    <title>ConvTranspose2d</title>
    <url>/2022/02/12/ConvTranspose2d/</url>
    <content><![CDATA[<h1 id="ConvTranspose2d的理解和计算"><a href="#ConvTranspose2d的理解和计算" class="headerlink" title="ConvTranspose2d的理解和计算"></a>ConvTranspose2d的理解和计算</h1><p>DeConv是Convolution的逆过程，但是和在Pytorch中却和Conv共享相同的参数，所以较难计算和理解。本文分析ConvTranspose2d的计算过程。<br><span id="more"></span></p>
<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>deconvolution反卷积在pytorch中的代码为<code>ConvTranspose2d</code>，是将图像从模糊转变成清晰的过程。</p>
<p>进行2D卷积/反卷积时：</p>
<ul>
<li>same inputs$i_1=i _2=i=4$</li>
<li>same kernel size$k_1=k_2=k=3$</li>
<li>same strides$s_1=s_2=s=1$</li>
<li>same zero padding$p_1=p_2=p=0$</li>
<li>same outputs$o_1=o_2=o$<br><img src="https://s2.ax1x.com/2019/09/18/n75lfs.gif" alt="卷积/反卷积"><br>但是由右侧的反卷积可以看到实际的zero padding为2，这个zero padding是如何计算的？</li>
</ul>
<h2 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h2><ul>
<li>对于convolution，其output map和input map有如下关系 <script type="math/tex; mode=display">
o=[\frac{i+2p-k}{s}]+1</script></li>
</ul>
<p>上式子可化为</p>
<script type="math/tex; mode=display">
i=so-s+k-2p=\frac{[o+(s-1)(o-1)]+[(k-1)+(k-2p-1)]-k}{1}+1</script><p>令$i’=o+(s-1)(o-1), p’=\frac{(k-1)+(k-2p-1)}{2}=k-p-1, k’=k, s’=1, o’=\frac{i’+2p’-k’}{s’}+1$</p>
<p>一般取kernel_size k=2, strides s=2, padding p=0, 此时deconvolustion的作用是将矩阵的一边变为原来的两倍；当i为偶数时（即deconvolution的输出为偶数），也可取k=3，s=2，p=1（same padding），实现放大为原来的两倍的作用。<br><a href="https://www.cnblogs.com/shine-lee/p/11559825.html">参考文章</a></p>
]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>DCGAN</title>
    <url>/2021/08/24/DCGAN/</url>
    <content><![CDATA[<h1 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h1><h2 id="Title-Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks"><a href="#Title-Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks" class="headerlink" title="Title: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"></a>Title: <font color = red>Unsupervised Representation Learning</font> with Deep Convolutional Generative Adversarial Networks</h2><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>CNN has been used in mutiple supervised tasks, but rarely used in unsupervised learning.<br>In comination with GAN, this article introduced DCGANs, showing convincing evidence of the power in generating data.<br><span id="more"></span></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>Target(In a nutshell): Build good image representations</li>
<li>Methods: Training GANs and later reusing parts of the generator and discriminator networks as future extractors</li>
<li>Target(in details): <ul>
<li>valuate a set of constraints on the architectural topology（拓扑结构） of Convolutional GANs that make them stable to train in most settings(DCGAN)</li>
<li>use the trained discriminators for image classification tasks, showing competitive performance with other unsupervised algorithms</li>
<li>Visualize the filters learnt by GANs, and show specific filters have learned to draw specific objects</li>
<li>Generators has interesting vector arithmetic properties, which allowing for easy manipulation of semantic(语义) qualities of generated samples</li>
</ul>
</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Representation-Learning-from-Unlabeled-Data"><a href="#Representation-Learning-from-Unlabeled-Data" class="headerlink" title="Representation Learning from Unlabeled Data"></a>Representation Learning from Unlabeled Data</h3><ul>
<li>K-means</li>
<li>auto-encoder</li>
<li>Deep belief networks<h3 id="Generating-Natural-Images"><a href="#Generating-Natural-Images" class="headerlink" title="Generating Natural Images"></a>Generating Natural Images</h3></li>
<li>Parametric methods</li>
<li>non-parametric models<ul>
<li>do matching from a database of existing images, often matching patches of images, have been used in <strong>texture synthesis</strong>, <strong>super-resolution</strong>, <strong>in-painting</strong></li>
</ul>
</li>
<li>Parameter models<ul>
<li>A variational sampling approach to generating images: suffer from being blurry</li>
<li>Using an iterative forward diffusion process</li>
<li>Generative Adversarial Networks</li>
<li>Laplacian Pyramid Extension to GANs: still suffered from the objects looking wobbly</li>
<li>A recurrent network and deconvolution network approach<h3 id="Visualizing-the-internal-of-CNNs"><a href="#Visualizing-the-internal-of-CNNs" class="headerlink" title="Visualizing the internal of CNNs"></a>Visualizing the internal of CNNs</h3>using a gradient descent on the inputs lets us inspect the ideal image that activates certain subsets of filters</li>
</ul>
</li>
</ul>
<h2 id="Approach-and-Model-Architecture"><a href="#Approach-and-Model-Architecture" class="headerlink" title="Approach and Model Architecture"></a>Approach and Model Architecture</h2><blockquote>
<p>HIstorical attempt to training GAN using CNN has been unsuccessful, for unstable training process and other reasons; This article changes the structure of CNN and resulted in stable training across a range of datasets and allowed for training higher resolution and deeper generative models.</p>
</blockquote>
<h3 id="All-convolutional-net"><a href="#All-convolutional-net" class="headerlink" title="All convolutional net"></a>All convolutional net</h3><p>Using <strong>all convolutional networks</strong> in place of <strong>deterministic spatial pooling functions and strided convolutions</strong> in generator and discriminator, which allowing all convolutional networks learning its own spatial upsampling.</p>
<h3 id="Trend-towards-eliminating-fully-connected-layers-on-top-of-convolutional-features"><a href="#Trend-towards-eliminating-fully-connected-layers-on-top-of-convolutional-features" class="headerlink" title="Trend towards eliminating fully connected layers on top of convolutional features"></a>Trend towards eliminating fully connected layers on top of convolutional features</h3><p>global average pooling increased model stability but hurt convergence speed, so this article proposed that <u>input and output would directly connected in generator and discriminator</u><br><img src="http://fang-bnn.gitee.io/image_bed/bed/DCGAN.png" alt="DCGAN"></p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>Directly apply Batch normalization to all layers would result in sample oscillation and model instability, thus this article <strong>avoid adding batch normalization</strong> in <strong>generator output layer and discriminator input layer</strong></p>
<h3 id="ReLU-activation"><a href="#ReLU-activation" class="headerlink" title="ReLU activation"></a>ReLU activation</h3><p>In contrast to original GAN paper(Using maxout activation), this article used <code>LeakyReLU</code> in other layer and <code>tanh</code> in output layer</p>
<p><img src="http://fang-bnn.gitee.io/image_bed/bed/Stable_GAN.png" alt="stable_GAN"></p>
<h2 id="Training-detail"><a href="#Training-detail" class="headerlink" title="Training detail"></a>Training detail</h2><ul>
<li>pre-processing: Scaling input image to range of <code>tanh</code> activation funcntion $[-1, 1]$</li>
<li>batchsize: mini-batch size of 128</li>
<li>weight initalization: zero-centered normalization distribution with stantard deviation 0.02</li>
<li>LeakyReLU: negative slope=0.2</li>
<li>Adam optimizer with $\beta=0.5$</li>
<li>learning rate = 0.0002</li>
</ul>
<h2 id="Using-GAN-as-feature-extractor-Discriminator"><a href="#Using-GAN-as-feature-extractor-Discriminator" class="headerlink" title="Using GAN as feature extractor(Discriminator)"></a>Using GAN as feature extractor(Discriminator)</h2><p>Omission</p>
<h2 id="Manipulating-the-generator-representation-Generator"><a href="#Manipulating-the-generator-representation-Generator" class="headerlink" title="Manipulating the generator representation(Generator)"></a>Manipulating the generator representation(Generator)</h2><p>Omission(The adding and substrating in generator model, reducing the data needed when facing a complex data distribution)</p>
<p>Original address: <a href="https://arxiv.org/abs/1511.06434v1">DCGAN</a></p>
]]></content>
      <categories>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>GAN</tag>
        <tag>Aritcle</tag>
      </tags>
  </entry>
  <entry>
    <title>CARE</title>
    <url>/2021/08/19/CARE/</url>
    <content><![CDATA[<h1 id="Title：Content-aware-image-restoration-pushing-the-limits-of-fluorescence-microscopy"><a href="#Title：Content-aware-image-restoration-pushing-the-limits-of-fluorescence-microscopy" class="headerlink" title="Title：Content-aware image restoration: pushing the limits of fluorescence microscopy"></a>Title：Content-aware image restoration: pushing the limits of fluorescence microscopy</h1><p>内容感知图像重建（基于内容的图像恢复，为什么是内容感知？）：推动了荧光显微镜的极限（什么极限？）<br>Highlights</p>
<ol>
<li>问题指向性明确，很直接地针对多个生物问题设计网络和算法，不按照常规套路进行（固定细胞-活细胞-生物学效应）</li>
<li>内容丰富，包含了去噪、投影、各向同性重建（三维数据）、超分辨重建、概率生成网络等几乎所有荧光显微图像重建可以包含地内容</li>
<li>评价方式丰富，不仅仅局限于常规地MSE等损失函数或是结构相似度方法，甚至在网络后又进行了分割和追踪等操作，用分割和追踪地效果评价网络地效果</li>
<li>新建了一套用于评估重建图像可靠性地评价算法</li>
<li>基于一般机器学习中地概念，将其适用于本文面对的科研问题，开发了新的方法。<span id="more"></span>
</li>
</ol>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p><span style="background-color: #c0ebd7">Fluorescence microscopy is a key driver of discoveries in the life sciences</span>: 荧光显微镜在生命科学领域的新发现中起到关键性的推动作用。</p>
<p><span style="background-color: #c0ebd7">with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample.</span>：但同时又受到显微镜光学特性、荧光发色团的化学性质和样品曝光时间的限制</p>
<p><span style="background-color: #c0ebd7">These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth</span>: 这些限制促使我们需要在成像速度，空间分辨率，曝光和成像深度上进行权衡。</p>
<p><span style="background-color: #c0ebd7">In this work we show how content-aware image restoration based on deep learning extends the range of biological phenomena observable by microscopy</span>: 在这一工作中，我们展示了基于深度学习的内容感知图像恢复技术是如何延展生物显微成像的范围的</p>
<p><span style="background-color: #c0ebd7">We demonstrate on eight concrete examples how microscopy images can be restored even if 60-fold fewer photons are used during acquisition</span>: 我们用8个具体的例子来说明甚至小于60倍光照强度获取的图像仍然可以用于显微图像的重建</p>
<p><span style="background-color: #c0ebd7">how near isotropic resolution can be achieved with up to tenfold under-sampling along the axial direction</span>：如何在沿轴向进行多达十倍的欠采样下，可以达到向同性的分辨率</p>
<p><span style="background-color: #c0ebd7">and how tubular and granular structures smaller than the diffraction limit can be resolved at 20-times-higher frame rates compared to state-of-the-art methods</span>：以及较最先进方法的20倍采样下，对于管状和颗粒状结构，如何实现突破衍射极限的成像</p>
<p><span style="background-color: #c0ebd7">All developed image restoration methods are freely available as open source software in Python, FIJI, and KNIME</span>：所有研发的图像恢复方法都可以通过python，fiji和KNIME等开源途径获取。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><span style="background-color: #c0ebd7">Fluorescence microscopy is an indispensable tool in the life sciences for investigating the spatio-temporal dynamics of cells, tissues, and developing organisms. Recent advances such as light-sheet microscopy structured illumination microscopy, and super-resolution microscopy, enable time-resolved volumetric imaging of biological processes within cells at high resolution</span>: 荧光显微镜是生命科学中一种必不可少的工具，用于探索细胞的时空动态以及发育过程中的组织，比如说最近的进展：光片显微镜、结构光显微镜和超分辨显微镜，使得我们能够以高分辨率对细胞内的生命过程进行一定时间分辨率的三维体积成像。</p>
<p><span style="background-color: #c0ebd7">The quality at which these processes can be faithfully recorded, however, is determined not only by the spatial resolution of the optical device used, but also by the desired temporal resolution, the total duration of an experiment, the required imaging depth, the achievable fluorophore density, bleaching, and photo-toxicity</span>: 而决定这一过程能否被真实地记录的，不仅仅与光学设备的空间分辨率有关，而且与要求的空间分辨率、总的持续实验时间、要求的成像深度、可达到的荧光强度、漂白和光毒性有关。</p>
<p><span style="background-color: #c0ebd7">These aspects cannot all be optimized at the same time—trade-offs must be made, for example, by sacrificing signal-to-noise ratio (SNR) by reducing exposure time to gain imaging speed</span>: 这些方面无法同时被优化，必须要做出权衡，比如通过牺牲信噪比以获取较高的成像速度。</p>
<p><span style="background-color: #c0ebd7">Such trade-offs are often depicted by a design space that has resolution, speed, light exposure, and imaging depth as its dimensions (Fig. 1a), with the volume being limited by the maximal photon budget compatible with sample health</span>: 这样的权衡可以用一个空间来描述，这个空间有分辨率、成像速度、曝光以及成像深度几个维度组成，他们被样品所能承受的最大光照强度所限制</p>
<hr>
<p><span style="background-color: #c0ebd7">These trade-offs can be addressed through optimization of the microscopy hardware, yet there are physical limits that cannot easily be overcome</span>: 这些权衡可以通过优化显微镜的硬件结构来解决，但是有些物理上的极限无法被轻易地突破。</p>
<p><span style="background-color: #c0ebd7">Therefore, computational procedures to improve the quality of acquired microscopy images are becoming increasingly important. Super-resolution microscopy, deconvolution, surface projection algorithms, and denoising methods are examples of sophisticated image restoration algorithms that can push the limit of the design space, and thus allow the recovery of important biological information that would be inaccessible by imaging along </span>: 因此，通过计算过程来提高所需的显微成像质量变得越来越重要。诞生了一些复杂的图像重建方法，他们够突破设计空间限制，从而能够恢复无法通过单独成像获得的重要生物学信息，比如超分辨显微镜、下采样、表面投影算法、去噪算法等。</p>
<p><span style="background-color: #c0ebd7">However, most common image restoration problems have multiple possible solutions, and require additional assumptions to select one solution as the final restoration</span>: 然而，多数普通的图像重建算法存在多种可能的解，而且需要额外的前提建设并选择一种作为最终的重建方法。</p>
<p><span style="background-color: #c0ebd7">These assumptions are typically general, for example, requiring a certain level of smoothness of the restored image, and therefore are not dependent on the specific content of the images to be restored</span>: 这些假设是比较通用的，比如说重建的图像需要一定程度的平滑，因此不依赖于图像所包含的特定内容。</p>
<p><span style="background-color: #c0ebd7">Intuitively, a method that leverages available knowledge about the data at hand ought to yield superior restoration results.</span>: 直观的说，如果有能够利用手头的数据相关信息的方法，就能够产生比较好的重建结果。</p>
<p><span style="background-color: #c0ebd7">Deep learning is such a method, because it can learn to perform complex tasks on specific data by employing multilayered artificial neural networks trained on a large body of adequately annotated example data</span>：深度学习就是这样一种方法，因为他能够通过多层人工神经网络来训练大量充分的标记数据集，从而完成和特定数据相关的复杂的任务。</p>
<p><span style="background-color: #c0ebd7">In biology, deep learning methods have, for instance, been applied to the automatic extraction of connectomes from large electron microscopy data, for classification of image based high-content screens, fluorescence signal prediction from label-free images, resolution enhancement in histopathology, or for single-molecule localization in super-resolution microscopy</span>: 在生物中，深度学习被应用于诸如在大量电子显微镜数据中提取突触结构等包含大量内容的图片分类任务，无标注图片的荧光信号预测、组织切片分辨率的提高或是超分辨显微镜中的单分子定位。</p>
<p><span style="background-color: #c0ebd7">However, the direct application of deep learning methods to image restoration tasks in fluorescence microscopy is complicated by the absence of adequate training data and the fact that it is impossible to generate them manually</span>：然而，深度学习在图像恢复中的直接应用被缺乏足够的训练数据以及他们无法人工生成而复杂化。</p>
<p><span style="background-color: #c0ebd7">We present a solution to the problem of missing training data for deep learning in fluorescence microscopy by developing strategies to generate such data.</span>：通过生成类似的数据的方法，我们展示了一种方法来解决深度学习中数据缺失带来的问题。</p>
<p><span style="background-color: #c0ebd7"> This enables us to apply common convolutional neural network architectures (U-Nets34) to image restoration tasks, such as image denoising, surface projection, recovery of isotropic resolution, and the restoration of sub-diffraction structures</span>: 这使得我们能够利用普通的卷积神经网络结构（Unet）来实现图像恢复任务，如图像去噪、表面投影、分辨率各向同性恢复和亚分辨结构的重建</p>
<p><span style="background-color: #c0ebd7">We show, in a variety of imaging scenarios, that trained content-aware image restoration (CARE) networks produce results that were previously unobtainable</span>: 我们展现了我们训练的内容感知图像重建网络在多种成像情境下都能够达到之前无法获得的结果。</p>
<p><span style="background-color: #c0ebd7">This means that the application of CARE to biological images transcends the limitations of the design space, pushing the limits of the possible in fluorescence microscopy through machine-learned image computation.</span>: 这意味着CARE在生物成像领域的应用突破了设计空间的限制，通过机器学习计算方法推动荧光显微镜的成像极限。</p>
<h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><p><span style="background-color: #c0ebd7">Images with a low SNR are difficult to analyze in fluorescence microscopy. </span>: 低信噪比的荧光显微图像往往难以分析。</p>
<p><span style="background-color: #c0ebd7">One way to improve SNR is to increase laser power or exposure times, which is usually detrimental to the sample, limiting the possible duration of the recording and introducing artifacts due to photo damage</span>: 提高信噪比的方法之一是增强激光能量或是曝光时间，但这往往对样品是有害的，因此限制了曝光持续的事件，而过长的曝光时间也往往会导致光损伤引起的伪影</p>
<p><span style='background-color: #c0ebd7'>An alternative solution is to image at low SNR, and later<br>to computationally restore acquired images</span>: 另一种可行的解决方法是成像较低的信噪比图像，通过计算的方法重建需要获取的图像。</p>
<p><span style='background-color: #c0ebd7'>Classical approaches, such as non-local-means denoising, can in principle achieve this, but without leveraging available knowledge about the data at hand.</span>: 经典的方法有<code>non-local-means denoising</code>，理论上能够实现，但是他并没有利用后验数据。</p>
<h2 id="Image-restoration-with-physically-acquired-training-data"><a href="#Image-restoration-with-physically-acquired-training-data" class="headerlink" title="Image restoration with physically acquired training data"></a>Image restoration with physically acquired training data</h2><blockquote>
<p>利用实际获得训练数据进行图像恢复</p>
</blockquote>
<p><span style='background-color: #c0ebd7'>To demonstrate the power of machine learning in biology, we developed CARE.</span>: 为了说明机器学习在生物学中的作用，我们开发了CARE</p>
<p><span style='background-color: #c0ebd7'>We first demonstrate the utility of CARE on microscopy acquisitions of the flatworm Schmidtea mediterranea, a model organism for studying tissue regeneration.</span>: 我们首先在一种组织再生的模式生物——地中海扁虫中证明了CARE在显微图像获取中的作用</p>
<p><span style='background-color: #c0ebd7'>This organism is exceptionally sensitive to even moderate amounts of laser light, exhibiting muscle flinching at desirable illumination levels even when anesthetized</span>: 这种生物对极其微量的激光仍然格外敏感，会在激光找到的位置出现肌肉抽搐的现象，甚至在被麻醉时也存在。</p>
<p><span style='background-color: #c0ebd7'>Using a laser power that reduces flinching to an acceptable level results in images with such low SNR that they are impossible to interpret directly</span>: 既要实现减少的肌肉抽搐现象，又要实现较低的信噪比，是不可能的。</p>
<p><span style='background-color: #c0ebd7'>Consequently, live imaging of S.mediterranea has thus far been intractable</span>: 因此，迄今为止，这种扁虫的实时成像一直是非常棘手的问题。</p>
<p><span style='background-color: #c0ebd7'>To address this problem with CARE, we imaged fixed worm samples at serveral laser intensities. We acquired well-registered pairs of images, a low-SNR image at laser power compatible with live imaging, and a high-SNR image, serving as a ground truth.</span>: 为了用CARE解决这一问题，我们用固定的扁虫样品进行了荧光成像。我们需要较好地一一匹配的图像，分别是适于活体成像，由低能激光激发的低信噪比成像，以及由高能激光激发的高信噪比图像，用作金标准。</p>
<p><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_F1b.png" alt="Fig1b"><br>$x_i$是较差光照条件下的数据，$y_i$是同一样品的相同视野较好光照条件下的数据，用这个数据对进行训练。最后应用在数据集上。</p>
<p><span style='background-color: #c0ebd7'>We then trained a convolutional neural network and applied the trained network to previously unseen live-imaging data of S. mediterranea</span>: 我们随后训练了卷积神经网络，并且将其用在了之前无法直接观察到的扁虫实时成像数据。</p>
<p><span style='background-color: #c0ebd7'>We used networks of moderate size(~10<sup>6</sup> parameters) based on the U-Net architectrue, together with a per-pixel similarity loss, for example absolute error.</span>: 我们使用了基于Unet 的较小的网络，以及用了单像素相似度损失作为损失函数(<mark>Supplementary Notes1 and 2</mark>)，比如说绝对误差。</p>
<p><span style='background-color: #c0ebd7'>We consistently obtained high-quality restorations, even if the SNR of the images was very low, for example, being acquired with a 60-fold reduced light dosage.</span>: 我们在固定条件下获得高质量的图像，尽管他的信噪比比较低，比如在低于60倍光照强度下获取的样本。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/Fig1cd.png" alt="Fig1cd"><br><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_F1d&#39;.png" alt="CARE_F1d&#39;"></p>
<p>NML即为之前提到的<code>non-local-means denoising</code>的方法。C1，C2，C3分别是较低激光强度较长曝光时长、较低曝光强度较短曝光时长和很低激光强度较短曝光时长下的数据。由d图右侧的box-dot plots可以看到，Network较NLM在他的评价体系下效果更好，虽然无论那种方法，他们的成像水平都随着环境变差变更差，但是很明显Network相对于NLM更加具有鲁棒性。</p>
<p><span style='background-color: #c0ebd7'>To quantify this observation, we measured the restoration error between prediction and groundtruth images for three different exposure and laser-power conditions</span>: 为了定量化观察结果，我们测量了在三种不同的测量环境下的预测和金标准的误差。</p>
<p><span style='background-color: #c0ebd7'>Both the normalized root-mean-square error (NRMSE) and the structural similarity index improved considerably compared with results obtained by several potent classical denoising methods</span>: 无论是归一化的均方根误差还是结构相似度，网络获得的重建结果都比传统的去噪方法好</p>
<p><span style='background-color: #c0ebd7'>We further observed that even a small number of training images (for example, 200 patches of size 64×64×16) led to<br>an acceptable image restoration quality</span>: 我们进一步观察了小数据量的训练（比如说200个64×64×16的数据量），效果可以接受(<mark>Supplementary Fig6</mark>)</p>
<p><span style='background-color: #c0ebd7'>Moreover, while training a CARE network can take several hours, the restoration time for a volume of size 1,024×1,024×100 was less than 20 s on a single graphics processing unit.</span>: 另外，训练一个网络需要花费几个小时，但是在单个计算单元上重1,024×1,024×100的数据量只需要少于20s。</p>
<p><span style='background-color: #c0ebd7'>In this case, CARE networks are able to take input data that are unusable for biological investigations and turn them into high-quality timelapse data, providing a practical framework for live-cell imaging of S. mediterranea.</span>: 在这个案例中，CARE网络能够将生物学研究中哪些不可见的数据转化为高质量的时间序列数据，为扁虫的活细胞成像提供了一个实际可行的框架。</p>
<hr>
<p><span style='background-color: #c0ebd7'>We next asked whether CARE improves common downstream analysis tasks in live-cell imaging, such as nuclei segmentation. We used confocal microscopy recordings of developing Tribolium castaneum (red flour beetle) embryos, and as before trained a network on image pairs of samples acquired at high and low laser powers </span>: 随后，我们想知道CARE能否提高一般的下游数据分析质量，比如说核分割。我们使用共聚焦显微镜记录了正在发育的红粉甲虫胚胎，并且像之前那样训练了成对的数据集。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_F1e.png" alt="CARE_F1e"></p>
<p><span style='background-color: #c0ebd7'>The resulting CARE network performed well even on extremely noisy, previously unseen live-imaging data </span>: 最后的CARE网络在大量被噪声淹没的数据中仍然有较好的表现</p>
<p><span style='background-color: #c0ebd7'>To test the benefits of CARE for segmentation, we applied a simple nuclei segmentation pipeline to raw and restored image stacks of T. castaneum. The results show that, compared to manual expert segmentation, the segmentation accuracy improved from SEG=0.47 on the classically denoised raw stacks to SEG=0.65 on the CARE restored volumes</span>: 为了测试CARE对分割质量的提升，我们对原始数据和重建数据进行了核分割（基于阈值的核分割算法）。结果表明，和人工分割相比，分割的精准度从原始数据的SEG=0.47提高到0.65（<a href="https://www.nature.com/articles/nmeth.4473">SEG指的是分割结果和金标准之间重叠的平均大小</a>）<br><a href="http://fang-bnn.gitee.io/image_bed/bed/CARE_SF8.png">具体分割方法和效果</a></p>
<p><span style='background-color: #c0ebd7'>Since this segmentation performance is achieved at substantially reduced laser power, the gained photon budget can now be spent on the imaging speed and light-exposure dimensions of the design space.</span>: 因为上述分割是在相对较弱的光照条件下进行的，所以这一部分光强的补偿可以用于提高成像速度和曝光时间。</p>
<p><span style='background-color: #c0ebd7'>This means that Tribolium embryos, when restored with CARE, can be imaged for longer and at higher frame rates, thus enabling improved tracking of cell lineages.</span>这意味着当我们用CARE实现对甲虫胚胎更高帧率和曝光时间的成像，从而能够改进对细胞系的跟踪。</p>
<p><span style='background-color: #c0ebd7'>Encouraged by the performance of CARE on two independent denoising tasks, we asked whether such networks can also solve more complex, composite tasks. </span>受到CARE在上述两种去噪任务中表现的鼓舞，我们尝试更加复杂的任务。</p>
<p><span style='background-color: #c0ebd7'> In biology it is often useful to image<br>a three-dimensional (3D) volume and project it to a two-dimensional (2D) surface for analysis, such as when studying cell behavior in developing epithelia of the fruit fly Drosophila melanogaster</span>: 在生物学中，对样本进行三维成像后，进行二维投影并分析，比如对果蝇上皮细胞发育过程中的细胞行为的研究。</p>
<p><span style='background-color: #c0ebd7'>Also, in this context, it is beneficial to optimize the trade-off between laser power and imaging speed, usually resulting in rather low-SNR images. </span>: 同时，在这个例子中，我们仍然需要权衡激光强度和成像速度之间的关系，否则常常会获得低信噪比图像。</p>
<p><span style='background-color: #c0ebd7'>Thus, this restoration problem is composed of projection and denoising, presenting the opportunity to test whether CARE networks can deal with such composite tasks.</span>: 因此，这个重建问题由两部分组成，包括投影和去噪，可以用来测试CARE能否胜任这种复杂的任务。</p>
<p><span style='background-color: #c0ebd7'>For training, we again acquired pairs of low- and high-SNR 3D image stacks, and further generated 2D projection images from the high-SNR stacks that serve as ground truth</span>: 为了训练，我们又获取了低信噪比和高信噪比的三维数据集，并用高信噪比的三维数据集投影获取了二维数据集作为金标准。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_F2a.png" alt="CARE_F2a"><br><span style='background-color: #c0ebd7'>We developed a task-specific network architecture that consists of two jointly trained parts: a network for surface projection, followed by a network for image denoising</span>: 我们开发了一种面向任务型的特殊网络结构，由两部分组成，第一个网络结构用于投影，第二个网络结构用于去噪。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_F2b.png" alt="CARE_F2b"><br>第一个Unet的网络结构用于生成2为的投影数据，第二个网络结构用了ResUnet，用于生成2维的去噪数据<br><a href="http://fang-bnn.gitee.io/image_bed/bed/CARE_3D22DNetwork.jpg">CARE_3D22DNetwork</a></p>
<p><span style='background-color: #c0ebd7'>The results show that with CARE, reducing light dosage up to tenfold has virtually no adverse effect on the quality of segmentation and tracking results obtained on the projected 2D images with an established analysis pipeline</span>: 这一结果表明CARE能够在降低10倍光照强度下实现对对分割和追踪无明显副作用的2为图像投影重建。</p>
<p><span style='background-color: #c0ebd7'>Even for this complex task, the gained photon budget can be used to move beyond the design space, for example, by increasing temporal resolution, and consequently improving the precision of tracking of cell behaviors during wing morphogenesis</span>: 甚至在这种复杂的重建任务中，获得的光子补偿能够用于超越设计空间的限制比如增强事件分辨率、提高翅膀形态发育的细胞行为的追踪精准度。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_Fwing.png" alt="CARE_F2c"><br><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_F2d.png" alt="CARE_F2d"><br>在这张图中可以类似的得出Network较经典的方法更加具有鲁棒性和重建能力，虽然差距并不是那么大，在supplementary fig把network和更多的经典重建方法比较（为什么不和更多的网络比较呢），并且用相同的分割方法（随机森林）对网络输出结果和输入进行分割，并用SEG作为指标，发现高曝光引起的漂白会降低传统方法重建后的分割效果，而网络则不会。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_SF12.png" alt="CARE_SF12"></p>
<h2 id="Image-restoration-with-semi-synthetic-training-data"><a href="#Image-restoration-with-semi-synthetic-training-data" class="headerlink" title="Image restoration with semi-synthetic training data"></a>Image restoration with semi-synthetic training data</h2><p>用半人工合成数据进行图像恢复</p>
<p><span style='background-color: #c0ebd7'>A common problem in fluorescence microscopy is that the axial resolution of volumetric acquisitions is substantially lower than the lateral resolution (some advanced modalities allow for isotropic acquisitions, such as multiview light-sheet microscopy)</span>: 一个在荧光显微镜中比较普遍存在的问题就是轴向的分辨率往往低于横向的分辨率（一些比较现先进的显微镜则不然，如<a href="https://www.nature.com/articles/nmeth.2064">多角度光片显微镜</a>）</p>
<p><span style='background-color: #c0ebd7'>This anisotropy compromises the ability to accurately measure properties such as the shapes or volumes of cells.</span>: 这一各向异性迫使我们在精准的测量细胞形状和体积上做出让步。</p>
<p><span style='background-color: #c0ebd7'>Anisotropy is caused by the inherent axial elongation of the optical point spread function (PSF), and the often low axial sampling rate of volumetric acquisitions required for fast imaging.</span>: 各向异性是由样品固有的特性造成的，即在光路的延长线上，轴向的点扩散函数和横向的点扩散函数不同，而且对高速成像而言，轴向成像速率相对较慢，所以只能牺牲轴向的分辨率。</p>
<p><span style='background-color: #c0ebd7'>For the restoration of isotropic image resolution, adequate pairs of training data cannot directly be acquired at the microscope.</span>: 为了恢复各向同性的图像，仅有由显微镜获取的数据对是不够的。</p>
<p><span style='background-color: #c0ebd7'>Rather, we took well-resolved lateral slices as ground truth, and computationally modified them (applying a realistic imaging model; Supplementary Note 2) to resemble anisotropic axial slices of the same image stack</span>: 我们将很好的分辨率的横向切片作为金标准，然后用计算的方法进行修饰以生成各向异性的轴向切片。</p>
<p><span style='background-color: #c0ebd7'>In this way, we generated matching pairs of images showing the same content at axial and lateral resolutions. </span>: 我们以这种方式生成了一一对应的分别以轴向分辨率和横向分辨率为标准的图片。</p>
<p><span style='background-color: #c0ebd7'>These semi-synthetically generated pairs are suitable to train a CARE network that then restores previously unseen axial slices to nearly isotropic resolution.</span>: 这些半合成的数据对适合用来训练CARE网络，这一网络能够将先前几乎不能分辨的轴向切片重建成和水平分辨率相近的水平。</p>
<hr>
<p><span style='background-color: #c0ebd7'></span>: 为了恢复整个各向异性的样品，我们将训练的网络应用于整块水平的切片上，并且采取了两个正交方向的平均作为单一的各向同性重建（xz/yz的平均）</p>
<ul>
<li><strong>重建的具体过程</strong></li>
</ul>
<ol>
<li>获取体素$g$，显微镜固有的点扩散函数$h$，轴向上采样因子$\sigma$。</li>
<li>对高分辨率的水平切片进行以下操作，以实现水平切片轴向切片化<ol>
<li>对轴向点扩散函数（一维）扩展成二维的点扩散函数，并对水平切片进行卷积</li>
<li>用轴向的上采样因子$\sigma$进行下采样</li>
</ol>
</li>
<li>对原始高分辨率水平切片和轴向切片化的水平切片采样（分割）后，进行训练。</li>
<li>对两个正交方向的切片：xz方向和yz方向进行重建，将对应体素平均，获得高分辨的轴向切片。</li>
</ol>
<hr>
<p><span style='background-color: #c0ebd7'>We applied this strategy to increase axial resolution of acquired volumes of fruit fly embryos, zebrafish retina, and mouse liver, imaged with different fluorescence imaging techniques. The results show that CARE improved the axial resolution in all three cases considerably</span>: 我们将这种方法应用于果蝇胚胎，斑马鱼视网膜，小鼠肝、用多种不同的荧光成像方法，这些结果都显示了CARE都大大提高了三种样品的轴向分辨率。</p>
<p><span style='background-color: #c0ebd7'>To quantify this, we performed Fourier spectrum analysis of Drosophila volumes before and after restoration, and showed that the frequencies along the axial dimension are fully restored, while frequencies along the lateral dimensions remain unchanged </span>: 为了证实这一点，我们对重建前和重建后的果蝇样本进行了傅里叶分析，发现轴向的分辨率得到了较好的重建，同时横向分辨率得到了保持。</p>
<p><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_SF16.png" alt="CARE_SF16"><br>从上图上就可以很好地说明问题，首先从信号来看，直观感受就是经过网络重建后很明显的清晰了，分辨率提高了，在频率空间中，横向的比较，应该是x方向的频率是接近的，即水平方向的分辨率保持的，而纵向蓝色是输入，红色是网络输出，可以看到在高频段红色明显要高于蓝色，说明重建后的分辨率确实提高了很多，且和横向的形状较为接近，说明纵向和横向分辨率接近。</p>
<p><span style='background-color: #c0ebd7'>Since the purpose of the fruit fly data is to segment and track nuclei, we applied a common segmentation pipeline to the raw and restored images, and observed that the fraction of incorrectly identified nuclei was reduced from 1.7% to 0.2%</span>: 因为以上果蝇胚胎数据是用来分割和跟踪核的移动的，我们将分割算法应用于初始数据（经过上采样）和重建图像，并且观察到错误率由原来的1.7%下降到了0.2%。</p>
<p><span style='background-color: #c0ebd7'>Thus, restoring anisotropic volumetric embryo images to effectively isotropic stacks leads to improved segmentation, and will enable more reliable extraction of developmental lineages.</span>: 因此将胚胎图像从各向异性重建成各向同性，能够提高分割，从而对发育细胞系的更可靠的提取。</p>
<p><span style='background-color: #c0ebd7'>While isotropic images facilitate segmentation and subsequent quantification of shapes and volumes of cells, vessels, or other biological objects of interest, higher imaging speed enables imaging of larger volumes and their tracking over time. Indeed, respective CARE networks deliver the desired axial resolution with up to tenfold fewer axial slices </span>: 这种各向同性的图片对分割和随后细胞、血管和生物对象的形状体积定量化成为可能，同时更高的成像速度有使得更大体积和对对象的追踪得以实现。事实上，这一网络的应用可以使轴向的数据量减少十倍。</p>
<p><span style='background-color: #c0ebd7'>allowing one to reach comparable results ten times faster. We quantified the effect of subsampling on raw and restored volumes with respect to restorations of isotropically sampled volumes for the case of the liver data</span>: 使得我们能以快10倍的速度获取同水平的图像。我们又将肝细胞原始数据二次采样结果、重建结果和各向同性采样结果进行对比。</p>
<p><span style='background-color: #c0ebd7'>Finally, we observed that for two-channel datasets such as the zebrafish, networks learned to exploit correlations between channels, leading to a better overall restoration quality compared to results based on individual channels.</span>: 最后，我们观察了如斑马鱼的双通道数据，发现神经网络能够探索两个通道之间的联系，使得重建效果较基于单个通道的效果更好。<mark>！！！SRTP</mark></p>
<p><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_SF15.png" alt="CARE_SF15"></p>
<h2 id="Image-restoration-with-synthetic-training-data"><a href="#Image-restoration-with-synthetic-training-data" class="headerlink" title="Image restoration with synthetic training data"></a>Image restoration with synthetic training data</h2><p>用合成数据进行训练</p>
<p><span style='background-color: #c0ebd7'>Having seen the potential of using semi-synthetic training data for CARE, we next investigated whether reasonable restorations can be achieved even from synthetic image data alone, that is, without involving real microscopy data during training.</span>: 见证了CARE在半合成数据上学习的潜力，我们接下来想试试在仅仅靠全部合成的图像数据进行训练，CARE能否完成合理的重建，也就是说在训练过程中完全不涉及真实地显微镜数据。</p>
<p><span style='background-color: #c0ebd7'>In most of the previous applications, one of the main benefits of CARE networks was improved imaging speed</span>: 在先前的应用中，CARE的主要优势在于能够提高成像速度。</p>
<p><span style='background-color: #c0ebd7'>Many biological applications additionally require the resolution of sub-diffraction structures in the context of live-cell imaging</span>: 在许多生物学的应用中，额外要求获取活细胞成像中的亚衍射结构。</p>
<p><span style='background-color: #c0ebd7'>Super-resolution imaging modalities achieve the necessary resolution, but suffer from low acquisition rates</span>: 超分辨成像能够达到必要的分辨率，但是受到低成像速率的限制。</p>
<p><span style='background-color: #c0ebd7'>In contrast, widefield imaging offers<br>the necessary speed, but lacks the required resolution. </span>: 相反，明场成像拥有必要的成像速度，但是缺乏所要求的分辨率。</p>
<p><span style='background-color: #c0ebd7'>We therefore tested whether CARE can computationally resolve sub-diffraction structures using only widefield images as input</span>: 我们于是测试了CARE能否只用明场成像作为输入解决亚衍射结构成像问题。</p>
<p><span style='background-color: #c0ebd7'>Note that this is a fundamentally different approach compared to recently proposed methods for single-molecule localization microscopy that reconstruct a single super-resolved image from multiple diffraction-limited input frames using deep learning</span>: 值得注意的是，这是一种和其他最近提出的单分子定位显微镜从根本上就不同的方法，单分子显微镜利用深度学习，将多张受限于衍射极限的输入图片；合成一张超分辨图片。</p>
<p><span style='background-color: #c0ebd7'> To this end, we developed synthetic generative models of tubular and point-like structures that are commonly studied in biology. </span>: 为此，我们开发了生成管状和点状结构的模型，这些结构在生物学中是受到普遍研究的。</p>
<p><span style='background-color: #c0ebd7'>To obtain synthetic image pairs for training, we used these generated structures as ground truth, and computationally modified them to resemble actual microscopy data</span>: 为了获取合成图像集的训练数据，我们将生成的这些结构作为金标准，并且将他们修饰成类似于真实的显微镜数据。</p>
<ul>
<li><p>生成策略</p>
<ul>
<li><p>微管模拟数据<br>  $\kappa<em>n=exp(2\pi i \times clip</em>{\kappa<em>{max}}[\kappa_0+\mathscr{W}_n(d</em>{\kappa})]),\ \ \ \mathscr{W}<em>n(d</em>\kappa)\sim\sum\limits<em>i^n\mathscr{N}(0, d</em>{\kappa})$</p>
<p>  $v<em>n=v_0\ exp(2\pi i\times \sum\limits</em>{i=0}^n \kappa_i)$</p>
<p>  $x<em>n = x_0+\sum\limits</em>{i=0}^nv_i$</p>
</li>
<li><p>囊泡模拟数据<br>  类似于微管数据的合成</p>
</li>
<li>人工噪声<br>  低频perlin噪声（背景荧光），PSF卷积、增加高斯和泊松相机噪声。</li>
</ul>
</li>
</ul>
<p><span style='background-color: #c0ebd7'>Specifically, we created synthetic ground-truth images of tubular meshes resembling microtubules, and point-like structures of various sizes mimicking secretory granules.</span>: 具体而言，我们创建了类似于微管的管状网格的合成图像作为金标准，以及模拟分泌颗粒的各种大小的点状结构。</p>
<p><span style='background-color: #c0ebd7'>Then we computed synthetic input images by simulating the image degradation process by applying a PSF, camera noise, and background auto-fluorescence </span>: 于是，我们模拟真实数据，为合成的结构添加了PSF，相机噪声和背景自动荧光</p>
<p><span style='background-color: #c0ebd7'>Finally, we trained a CARE network on these generated image pairs, and applied it to two-channel widefield time-lapse images of rat INS-1 cells where the secretory granules and the microtubules were labeled.</span> 最后我们利用这些合成的数据集进行训练，并且将训练好的网络应用于INS-1细胞的双通道数据中，其中的分泌囊泡和微管被标注。</p>
<p><span style='background-color: #c0ebd7'>We observed that the restoration of both microtubules and secretory granules exhibited a dramatically improved resolution, revealing structures imperceptible in the widefield images.</span>: 我们观察到重建的分泌囊泡和微管图像的分辨率都得到了极大的提升，解释了明场图像中难以察觉的细节结构。</p>
<p><span style='background-color: #c0ebd7'>To substantiate this observation, we compared the CARE restoration to the results obtained by deconvolution, which is commonly used to enhance widefield images, Line profiles through the data show the improved performance of the CARE network over deconvolution </span>: 为了证实这个现象，我们将CARE重建结果和去卷积比较, 通过线剖面的数据显示了 CARE 网络在反卷积方面的改进性能。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_F4b.png" alt="CARE_F4b"></p>
<p><span style='background-color: #c0ebd7'>We additionally compared results obtained by CARE with those from superresolution radial fluctuations (SRRF), a state-of-the-art method for reconstructing super-resolution images from widefield timelapse data</span>: 我们又比较了通过CARE重建结果和SRRF重建结果。</p>
<p><span style='background-color: #c0ebd7'>We applied both methods on time-lapse widefield images of GFP-tagged microtubules in HeLa cells. The results show that both CARE and SRRF are able to resolve qualitatively similar microtubular structures </span>: 我们将两种方法都应用于GFP标记的海拉微管时序明场图。这些结果显示CARE和SRRF都能够实现性质相似的微管结构重建。</p>
<p><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_F4c.png" alt="CARE_F4c"><br>可以看到，Network的重建效果在背景噪声上明显要由于SRRF重建的，因为模拟数据的金标准的背景是比较好的，我觉得我们通过SRRF做金标准重建的效果也绝对没有模拟数据的效果好。</p>
<p><span style='background-color: #c0ebd7'>However, CARE reconstructions enable imaging to be carried out at least 20 times faster, since they are computed from a single average of up to 10 consecutive raw images while SRRF required about 200 consecutive widefield frames</span>: 然而，CARE重建图像的速度是SRRF的20倍，因为CARE重建结果是由10帧连续图像平均所得的一张图像计算所得，而SRRF需要连续的200帧明场图像。</p>
<p><span style='background-color: #c0ebd7'>We also used SQUIRREL to quantify<br>the error for both methods and observed that CARE generally produced better results, especially in image regions containing overlapping structures of interest</span>: 我们用SQUIRREL进行定量分析error map和RSE，发现在微管重叠量较大的地方，重建效果较SRRF更好。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_SF23.png" alt="CARE_SF23"><br>这张图可以有两组对照，第一组是两个时间点的对照，第二组是有背景和无背景的对照。时间序列上的对照可以看到随着时间增加， 误差是有一种微弱的减小的趋势的，这个感觉没啥好分析的。另外一个是在微管密度高，也就是这里的R2，without background中，Network的重建效果要远好于SRRF重建效果；而在微观密度较低，如这里的R1中，SRRF和Network重建较为接近。作者在这里写的原因和我之前在上面写的类似，是因为生成数据中的金标准的是没有背景荧光的。</p>
<p><span style='background-color: #c0ebd7'>Taken together, these results suggest that CARE networks can enhance widefield images to a resolution usually obtainable only with super-resolution microscopy, yet at considerably higher frame rates</span>: 总的来说，这些结果说明CARE网络能够提高明场图像的分辨率，在较快的拍摄速率下实现超分辨显微镜才能达到的分辨率。</p>
<h2 id="Reliablility-of-image-restoration"><a href="#Reliablility-of-image-restoration" class="headerlink" title="Reliablility of image restoration"></a>Reliablility of image restoration</h2><p>深度学习图像重建的可靠性</p>
<p><span style='background-color: #c0ebd7'>We have shown that CARE networks perform well on a wide range of image restoration tasks, opening up new avenues for biological observations</span>我们展示了CARE网络能够胜任较为广泛的图像重建任务，开生物成像之先路。</p>
<p><span style='background-color: #c0ebd7'>However, as for any image processing method, the issue of reliability of results needs to be addressed</span>: 但与此同时，我们也需要关注结果的可靠性。</p>
<p><span style='background-color: #c0ebd7'>CARE networks are trained for a specific biological organism, fluorescent marker, and microscope setting. When a network is applied to data it was not trained for, results are likely to suffer in  uality, as is the case for any (supervised) method based on machine learning</span>: CARE网络为特定条件下的生物结构、荧光标记和显微镜参数进行训练。当CARE被用于不匹配的数据训练时，可能会导致重建效果不好，这是所有监督学习都存在的问题。</p>
<p><span style='background-color: #c0ebd7'>Nevertheless, we observed only minimal ‘hallucination’ effects, where structures seen in the training data erroneously appear in restored images </span>: 然而，我们还是观察到了叫少量的幻觉效应，即训练集中的结构出现在了重建的图像中，在SF25a中，展示了较大的两个误差。</p>
<ul>
<li>误差汇总<ul>
<li>异源数据产生的重建误差<br>  <img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_SF24.png" alt="CARE_SF24"><br>  误差较为明显</li>
<li>其他误差<br>  <img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_SF25.png" alt="CARE_SF25"><br>  a: 当在极低的信噪比情况下进行数据重建时，会出现较大的误差如结构的增加或是结构的消失。说明网络还是不够强大。<br>  b: 归一化错误：在训练时，数据被归一化为$(p<em>{min}, p</em>{max})=(2\%/99.7\%)$，而在测试时，数据被归一化为$(p<em>{min}, p</em>{max})=(1\%/30\%)$，把最强的信号定位在了第30%的位置，导致信号较弱背景位置出现了大量噪点。<br>  c：图片缩放，对一个网络而言，其输入图像对应的像素点尺寸和PSF都是固定的。如果用他来训练错误缩放的图像，就会出现问题。</li>
</ul>
</li>
</ul>
<p><span style='background-color: #c0ebd7'>Nevertheless, it is essential to identify cases where the above mentioned problems occur. To enable this, we changed the last network layer so that it predicts a probability distribution for each pixel</span>: 然而，我们有必要明确什么时候以上问题会发生，为了解决这个问题，我们改变了网络的最后一层以预测每个像素点的分布。</p>
<p><span style='background-color: #c0ebd7'>We chose a Laplace distribution for simplicity and robustness.</span>: 我们采用拉普拉斯分布，因为他具有简洁性和鲁棒性。</p>
<p><span style='background-color: #c0ebd7'>For probabilistic CARE networks, the mean of the distribution is used as the restored pixel value, while the width (variance) of each pixel distribution encodes the uncertainty of pixel predictions</span>: 对于概率CARE网络，分布的平均代表了重建像素的值，而方差代表了每个像素预测的不确定性。</p>
<p><span style='background-color: #c0ebd7'>Intuitively, narrow distributions signify high confidence, whereas broad distributions indicate low-confidence pixel predictions. This allows us to provide per-pixel confidence intervals of the restored<br>image </span>: 比较直观的来看，比较窄的分布具有比较高的置信度，然而比较宽的分布说明单个像素的预测的置信度比较低。这位我们提供了重建图像的逐像素置信区间。</p>
<p><span style='background-color: #c0ebd7'>We observed that variances tend to increase with restored pixel intensities.</span>: 我们观察到方差随着重建像素的强度增强而增强。</p>
<p><span style='background-color: #c0ebd7'>This makes it hard to intuitively understand which areas of a restored image are reliable or unreliable from a static image of per-pixel variances</span>:因此，仅仅依靠静态地像素方差数据，难以直观地理解图像的某一块重建区域是可靠的或是不可靠的。</p>
<p><span style='background-color: #c0ebd7'>Therefore, we visualize the uncertainty in short video sequences, where pixel intensities are randomly sampled from their<br>respective distributions </span>: 因此，我们用短序列的方式可视化不确定性，在这些短序列中，像素的强度是从他们的分布中随机采样的。</p>
<p><span style='background-color: #c0ebd7'>We additionally reasoned that by analyzing the consistency of predictions from several trained models we can assess their reliability. </span>: 我们还推断，通过分析来自几个训练模型的预测的一致性，我们可以评估它们的可靠性。</p>
<p><span style='background-color: #c0ebd7'>To that end, we train ensembles of about five CARE networks on randomized sequences of the same training data</span>: 为了实现这一点，我们以将训练数据随机打乱，训练了一组CARE网络。</p>
<p><span style='background-color: #c0ebd7'>We introduced a measure D that quantifies the probabilistic ensemble disagreement per pixel. D takes values<br>between 0 and 1, with higher values signifying larger disagreement, that is, smaller overlap among the distributions predicted by the networks in the ensemble.</span>: 我们又引入了一种测度D, 用于定量化一组概率网络对单个像素预测的不一致性。D在0到1之间取值，值越高，代表不一致性越强，也就是说网络之间的重合度越小。</p>
<p><span style='background-color: #c0ebd7'>Using fly wing denoising as an example, we observed that in areas where different networks in an ensemble predicted very similar structures, the disagreement measure D was low.</span>: 以果蝇翅膀的降噪为例，我们观察到在那些网络预测结果相似的地方，D非常低，在网络结果不相似的地方，D值非常高。</p>
<p><span style='background-color: #c0ebd7'>Therefore, training ensembles of CARE networks is useful for detecting problematic image areas that cannot reliably be restored. </span>: 因此训练一组CARE网络能够检测不可靠的重建的区域。</p>
<h1 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h1><p><span style='background-color: #c0ebd7'>We have introduced CARE networks designed to restore fluorescence microscopy data.</span>: 我们介绍了CARE网络，它设计被用于重建荧光显微图像。</p>
<p><span style='background-color: #c0ebd7'>A key feature of our approach is that the generation of training data does not require laborious manual training data generation.</span>: 我们方法的一个关键的特点，是我们自己生成训练数据，而不需要实验室人工拍摄以生成训练数据。</p>
<p><span style='background-color: #c0ebd7'>With CARE, flatworms can be imaged without unwanted muscle contractions, beetle embryos can be imaged much more gently and therefore for longer and much faster, large tiled scans of entire Drosophila wings can be imaged and simultaneously projected at dramatically increased temporal resolution, isotropic restorations of embryos and large organs can be computed from existing anisotropic data, and sub-diffraction structures can be restored from widefield systems at high frame rates</span>: 有了CARE，就可以拍摄无肌肉收缩的扁虫的成像；甲虫胚胎可以在更加微弱的光照下进行曝光时间更长，帧率更高的成像；大面的完整的果蝇翅膀能够被同时以更高的时间分辨率投影、成像；胚胎和大器官能够由各向异性重建为各向同性；并且亚衍射极限结构能够由明场下高帧率获取的图像下重建得到。</p>
<p><span style='background-color: #c0ebd7'>In all these examples, CARE allows the photon budget saved during imaging to be invested into improvement of acquisition parameters relevant for a given biological problem, such as speed of imaging, phototoxicity, isotropy, and resolution</span>: 在所有的例子中，CARE能够让光子预算在成像过程中得到保存，并用于提高与特定生物问题相关的参数，如成像速度、曝光时间、光毒性和分辨率</p>
<p><span style='background-color: #c0ebd7'>Whether experimentalists are willing to make the above-mentioned investment depends on their trust that a CARE networ k is accurately restoring the image</span>: 研究人员是否愿意用CARE依赖于他们是否愿意相信网络能够精确地重建图像。</p>
<p><span style='background-color: #c0ebd7'>This is a valid concern that applies to every image restoration approach.</span>： 这是一个每种图像重建方法都存在的实际问题。</p>
<p><span style='background-color: #c0ebd7'>What sets CARE apart is the availability of additional readouts, that is, per-pixel confidence intervals and ensemble disagreement scores, which  allow users to identify image regions where restorations might not be accurate</span>: 让CARE不同的是，它存在另外的输出，也就是说逐像素置信区间和网路组不一致因素，让我们能够验证图像区域的哪些区域可能没有得到精准重建。</p>
<p><span style='background-color: #c0ebd7'>We have shown multiple examples where image restoration with CARE networks positively impacts downstream image analysis, such as segmentation and tracking of cells needed to extract developmental lineages</span>:  我们展示了大量的例子，这些例子中都展现了CARE重建的结果能够积极地影响下游地图像分析，比如分割和追踪那些需要提取的发育细胞系。</p>
<p><span style='background-color: #c0ebd7'>Interestingly, in the case of Tribolium, CARE improved segmentation by efficient denoising, whereas in the case of Drosophila, the segmentation was improved by an increase in the isotropy of volumetric acquisitions</span>: 有意思的是，在甲虫的例子中，去噪能够提高分割的效果、在果蝇的例子中，各向同性化能够提高分割的效果。</p>
<p><span style='background-color: #c0ebd7'>These two benefits are not mutually exclusive and could very well be combined. In fact, we have shown on data from developing Drosophila wings that composite tasks can be jointly trained. Future explorations of joint training of composite networks will further broaden the applicability of CARE to complex biological imaging problems</span>: 这两个优点并不矛盾，并且可以很好地结合；</p>
<p><span style='background-color: #c0ebd7'>In fact, we have shown on data from developing Drosophila wings that composite tasks can be jointly trained. Future explorations of joint training of composite networks will further broaden the applicability of CARE to complex biological imaging problems</span>: 事实上，我们由果蝇翅膀的数据可以展示，CARE可以训练复合的任务，进一步对符合任务的网络探索能够进一步拓宽CARE在复杂生物成像问题中的应用。</p>
<p><span style='background-color: #c0ebd7'>However, CARE networks cannot be applied to all existing image restoration problems. </span>: 然而，CARE网络不能够用于所有的图像重建问题。</p>
<p><span style='background-color: #c0ebd7'>For instance, the proposed isotropic restoration relies on the implicit assumption that structures of interest do appear in arbitrary orientations and that the PSF is constant throughout the image volume.</span>: 比如，提出的各向同行重建方法是基于样品中的结构是朝着任意方向的，并且PSF在整个样品中相同的假设。</p>
<p><span style='background-color: #c0ebd7'> This assumption is only approximately true, and becomes increasingly worse as the imaging depth in the sample tissue increases.</span>: 这一假设只是大致正确，比如当样品深度更深时，情况会变得更糟。</p>
<p><span style='background-color: #c0ebd7'>Additionally, because of the nonlinear nature of neural network predictions, CARE must not be used for intensity-based quantifications such as, for example, fluorophore counting</span>: 另外，因为神经网络的非线性，CARE绝对不能用于基于荧光强度的定量分析，比如说荧光量的计数。</p>
<p><span style='background-color: #c0ebd7'>Furthermore, the disagreement score we introduced may be useful to additionally identify instances where training and test data are incompatible, that is, when a CARE network is applied on data that contain biological structures absent from the training set</span>: 更进一步的，我们提出的不一致性可能在训练和测试数据不一致时发挥作用，即CARE网络测试数据集中出现包含训练数据集中未出现的结构。</p>
<p><span style='background-color: #c0ebd7'>Overall, our results show that fluorescence microscopes can, in combination with CARE, operate at higher frame rates, shorter exposures, and lower light intensities, while reaching higher resolution, and thereby improving downstream analysis.</span>: 总而言之，我们的结果展示了CARE与荧光显微镜结合后，能够以更高帧率、更短曝光时间，更低的光强度实现更高的分辨率，从而提高下游的图像分析。</p>
<p><span style='background-color: #c0ebd7'>The technology described here is readily accessible to the scientific community through the open source tools we provide.</span>: 以上提到的技术都是开源的</p>
<p><span style='background-color: #c0ebd7'>We predict that the current explosion of image data diversity and the ability of CARE networks to automatically adapt to various image contents will make such learning approaches prevalent for biological image restoration and will open up new windows into the inner workings of biological systems across scales</span>: 我们断定，在当前爆发式的大量图像数据和CARE网络能够自动适应多种成像内容的能力的促进下，这一深度学习的方法将会在生物成像重建中得到较好的应用，并且为跨尺度的生物研究打开一扇新窗口。</p>
<hr>
<h1 id="图像重建的可靠性分析"><a href="#图像重建的可靠性分析" class="headerlink" title="图像重建的可靠性分析"></a>图像重建的可靠性分析</h1><p>图像重建的不确定性可以分为两种：Aleatoric uncertainty（随机不确定性），是一种固然存在的不确定性，如显微镜的相机永远都不可能捕捉图像的真实值；Epistemic uncertainty（认知不确定性），可以通过不断地补充信息从而减少的，可以通过增加数据量而减少。<em>举个例子就比如说在晚上对某些物体用手机拍照，噪点很多，但是通过增加曝光时间，可以让图像更清晰些，但是始终无法达到真实地记录这个物体所有信息地目的</em></p>
<h2 id="随机不确定性"><a href="#随机不确定性" class="headerlink" title="随机不确定性"></a>随机不确定性</h2><ul>
<li>MSE</li>
</ul>
<script type="math/tex; mode=display">
L_{\mathrm{mse}}(\theta)=\frac{1}{T} \frac{1}{N} \sum_{t=1}^{T} \sum_{i=1}^{N}\left(y_{i}^{t}-g_{\theta}\left(x^{t}\right)_{i}\right)^{2}\ \ \ \ \ \ (3.1)</script><ul>
<li>MSE等效于高斯分布地极大似然估计：</li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
\mathcal{L}_{\text {gauss }}^{\text {homoscedastic }}(\theta) &=\prod_{t=1}^{T} \prod_{i=1}^{N} p_{\text {gauss }}\left(y_{i}^{t} ; g_{\theta}\left(x^{t}\right)_{i}, \sigma\right) \quad \text { with } \\
p_{\text {gauss }}(z ; \mu, \sigma) &=\frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{(z-\mu)^{2}}{2 \sigma^{2}}\right)
\end{aligned}\ \ \ \ \ \ (3.2 \&3.3)</script><script type="math/tex; mode=display">
\begin{aligned}
\underset{\theta}{\arg \max } \mathcal{L}_{\text {gauss }}^{\text {homoscedastic }}(\theta) &=\underset{\theta}{\arg \min }-\log \mathcal{L}_{\text {gauss }}^{\text {homoscedastic }}(\theta) \\
&=\underset{\theta}{\arg \min } \sum_{t=1}^{T} \sum_{i=1}^{N} \frac{\left(y_{i}^{t}-g_{\theta}\left(x^{t}\right)_{i}\right)^{2}}{2 \sigma^{2}}+\log \sqrt{2 \pi \sigma^{2}} \\
&=\underset{\theta}{\arg \min } L_{\mathrm{mse}}(\theta)
\end{aligned}\ \ \ \ \ \ (3.4\&3.5\&3.6)</script><ul>
<li>拉普拉斯分布与概率网络</li>
</ul>
<script type="math/tex; mode=display">
p_{\text {laplace }}(z ; \mu, \sigma)=\frac{1}{2 \sigma} \exp \left(-\frac{|z-\mu|}{\sigma}\right)\ \ \ \ \ \ (3.7)</script><script type="math/tex; mode=display">
g_{\theta}(x)_{i}=p_{\text {laplace }}\left(\mu_{\theta}(x)_{i}, \sigma_{\theta}(x)_{i}\right)\ \ \ \ \ \ (3.8)</script><ul>
<li>损失函数</li>
</ul>
<script type="math/tex; mode=display">
L_{\text {laplace }}(\theta)=\frac{1}{T} \frac{1}{N} \sum_{t=1}^{T} \sum_{i=1}^{N} \frac{\left|y_{i}^{t}-\mu_{\theta}\left(x^{t}\right)_{i}\right|}{\sigma_{\theta}\left(x^{t}\right)_{i}}+\log \sigma_{\theta}\left(x^{t}\right)_{i}\ \ \ \ \ \ (3.9)</script><ul>
<li>预测输出</li>
</ul>
<script type="math/tex; mode=display">
\hat{y}_{i}=\mathbb{E}\left[g_{\theta}(x)_{i}\right]=\mu_{\theta}(x)_{i}\ \ \ \ \ \ (3.11)</script><h2 id="认知不确定性"><a href="#认知不确定性" class="headerlink" title="认知不确定性"></a>认知不确定性</h2><p>（一些理论和大量参考文献铺垫已省略）：</p>
<ul>
<li>最终分布<br>训练一组网络（输出结果不同）<br>得到最终分布。其中$\Theta={\theta<em>M}^M</em>{m=1}$，它既包含了随机不确定性参数，又包含了认知不确定性参数，因此可以代表整体的不确定性。</li>
</ul>
<script type="math/tex; mode=display">
g_{\Theta}(x)_{i}=\frac{1}{M} \sum_{m=1}^{M} p_{\text {laplace }}\left(\mu_{\theta_{m}}(x)_{i}, \sigma_{\theta_{m}}(x)_{i}\right)\ \ \ \ \ \ (3.13)</script><h2 id="验证和评估"><a href="#验证和评估" class="headerlink" title="验证和评估"></a>验证和评估</h2><h3 id="Reliablility-diagram"><a href="#Reliablility-diagram" class="headerlink" title="Reliablility diagram"></a>Reliablility diagram</h3><p><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_SF26.png" alt="CARE_SF26"></p>
<p>(省略了部分铺垫和参考文献，大致讲述了分类问题中的网络性能验证方法)</p>
<p>这里只讲述在这篇文章中的操作方法。</p>
<p>首先我们已经有了每个像素的分布$q<em>i=g</em>{\Theta}(x)_i$，每个像素预测的结果$\hat{y}_i$，我们对置信率和准确率进行计算。</p>
<script type="math/tex; mode=display">
\begin{aligned}
\operatorname{accuracy}(S, \epsilon) &=\frac{1}{|S|} \sum_{i \in S} \mathbf{1}\left[y_{i} \in A_{i}^{\epsilon}\right] &=\frac{1}{|S|} \sum_{i \in S} 1\left[y_{i} \in\left[\hat{y}_{i}-\epsilon, \hat{y}_{i}+\epsilon\right]\right] \\
\operatorname{confidence}(S, \epsilon) &=\frac{1}{|S|} \sum_{i \in S} \hat{r}_{i}^{\epsilon} \quad &=\frac{1}{|S|} \sum_{i \in S} \int_{\hat{y}_{i}-\epsilon}^{\hat{y}_{i}+\epsilon} q_{i}(z) d z
\end{aligned}\ \ \ \ \ \ (3.16\&3.17)</script><p>其中$\epsilon$是人为设定的超参数，用于控制置信区间的范围。如果$y_i$落在了置信区间范围内，那么就算作”分类正确”，置信度就通过积分计算。</p>
<p>这里的S算是对置信度的一个区间分类，对于每一个区间都计算区间内的置信度和准确度。</p>
<p>S的分类方法：$S<em>k^\epsilon={i\in G: \hat{r}_i\in(\tau_k, \tau</em>{k+1}]}$</p>
<p>最后用ECE表示</p>
<script type="math/tex; mode=display">
\operatorname{ECE}(\epsilon)=\sum_{k=1}^{K} \frac{\left|S_{k}^{\epsilon}\right|}{N}\left|\operatorname{accuracy}\left(S_{k}^{\epsilon}, \epsilon\right)-\operatorname{confidence}\left(S_{k}^{\epsilon}, \epsilon\right)\right|\ \ \ \ \ \ (3.18)</script><h3 id="网络组的不一致性"><a href="#网络组的不一致性" class="headerlink" title="网络组的不一致性"></a>网络组的不一致性</h3><p>用KL散度表示，KL散度是基于熵的概念，而熵能够用来衡量一个分布混乱程度，或者说信息量的大小，KL从公式上看就是相对熵，即一个分布相对另一个分布的熵，可以简单地理解为两个分布的相近程度。</p>
<script type="math/tex; mode=display">
D_{\mathrm{KL}}(p \| q)=\int p(z) \log \frac{p(z)}{q(z)} d z=[\underbrace{-\int p(z) \log q(z) d z}_{H(p, q)}]-[\underbrace{-\int p(z) \log p(z) d z}_{H(p)}]\ \ \ \ \ \ (3.19)</script><p>放到这篇文章中就可以表示为</p>
<script type="math/tex; mode=display">
\mathcal{D}(x)_{i}=\frac{1}{M} \sum_{m=1}^{M} D_{\mathrm{KL}}\left(g_{\theta_{m}}(x)_{i} \| g_{\Theta}(x)_{i}\right)\ \ \ \ \ \ (3.20)</script><p>对于当个网络而言，其对平均分布的KL散度可以表示为</p>
<script type="math/tex; mode=display">
\begin{aligned}
D_{\mathrm{KL}}\left(q_{m}^{i} \| q^{i}\right) &=\int q_{m}^{i}(z) \log \frac{q_{m}^{i}(z)}{\frac{1}{M} \sum_{m^{\prime}=1}^{M} q_{m^{\prime}}^{i}(z)} d z \\
&=\log M+\int q_{m}^{i}(z) \underbrace{\left[\log q_{m}^{i}(z)-\log \sum_{m^{\prime}=1}^{M} q_{m^{\prime}}^{i}(z)\right]}_{\leq 0} d z \\
& \leq \log M
\end{aligned}</script><p>对以上式子取极限，当每个网络的对应像素分布都相同时，KL散度为0，当每种分布的支撑集的交集是空集时（也就是说，一种分布不为0的地方，其他分布都是0），上面的≤取到等号，最大值为$\log M$.</p>
<p>最后对这KL散度用最大值和最小值进行归一化，得到文章中用到的不一致性衡量的标准，其中D越接近于0，一致性越好，越接近于1，一致性越差</p>
<script type="math/tex; mode=display">
\widehat{\mathcal{D}}(x)_{i}=\frac{1}{\log M} \mathcal{D}(x)_{i}=\frac{1}{M \log M} \sum_{m=1}^{M} D_{\mathrm{KL}}\left(g_{\theta_{m}}(x)_{i} \| g_{\Theta}(x)_{i}\right)</script><p>最后通过分析，可以看到在训练数据和验证数据一致的情况下，D较小，而在不一致的情况下，D较大。</p>
<p><img src="http://fang-bnn.gitee.io/image_bed/bed/CARE_SF28.png" alt="CARE_SF28"></p>
<p><a href="https://www.nature.com/articles/s41592-018-0216-7">论文地址</a></p>
]]></content>
      <categories>
        <category>Article translation</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>Microscope</tag>
        <tag>Super resolution</tag>
        <tag>Article</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN</title>
    <url>/2021/08/24/GAN/</url>
    <content><![CDATA[<h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Training target</strong>: In the space of arbitrary function $G$ and $D$, a unique solution exists, with $G$ recovering the training data distribution and $D$ equal to $\frac{1}{2}$ everywhere.</li>
<li>Advantage: There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. <span id="more"></span>
</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>Difficulties: Deep <em>Generative</em> models have had less of an impact, due to the difficulty of approximating many intractable probablilistic computations that arise in maximum likelihood estimation and related strategies.</li>
<li>Principle: <ul>
<li>Generative: A multilayer perceptron</li>
<li>Discriminative model: A multilayer perceptron<h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><a href="Generative_Models.md">Generative Model</a><h2 id="Adversarial-nets"><a href="#Adversarial-nets" class="headerlink" title="Adversarial nets"></a>Adversarial nets</h2><h3 id="Core-Function"><a href="#Core-Function" class="headerlink" title="Core Function"></a>Core Function</h3><script type="math/tex; mode=display">
\mathop{min}\limits_{G}\mathop{max}\limits_{D}V(D, G)=\mathbb{E}_{\mathbb{x}\sim p_{data}}[logD(\mathbf{x})]+\mathbb{E}_{\mathbb{z}\sim p_{\mathbf{z}}(\mathbf{z})}[log(1-D(G(\mathbf(\mathbf{z})))]</script><h3 id="Worth-taking-note-when-training"><a href="#Worth-taking-note-when-training" class="headerlink" title="Worth taking note when training"></a>Worth taking note when training</h3></li>
</ul>
</li>
<li>Optimizing D to completion in the inner loop of training is computationally prohibitive, and on finite datasets would result in overfitting.Instead, we alternate betwwen k steps of optimizing D and one step of optimizing G.</li>
<li>At begining, G is so poor that D could easily discriminate pictures, so $log(1-D(G(z)))$ always saturates, wo rather than training G to minimize $log(1-D(G(z)))$, we can train G to maximize $log(D(G(z)))$, providing stronger gradients early in learning.</li>
</ul>
<h2 id="Theoretical-Results"><a href="#Theoretical-Results" class="headerlink" title="Theoretical Results"></a>Theoretical Results</h2><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><blockquote>
<p>Minibatch stochastic gradient descent training of generative adversarial nets. The number of steps to apply to the discriminator, k, is a hyperparameter. We used k = 1, the least expensive option, in our experiments.</p>
</blockquote>
<hr>
<p><strong>for</strong> number of training iterations <strong>do</strong><br>&emsp;<strong>for</strong> k steps <strong>do</strong><br>&emsp;&emsp;Sample minibatch of m noise sample {z<sup>(1)</sup>, …, z<sup>(m)</sup>} from noise prior p<sub>g</sub>(z)<br>&emsp;&emsp;Sample minibatch of m examples {x<sup>(1)</sup>, …, x<sup>(m)</sup>} from data generating distribution $p_{data}(\mathbf{x})$<br>&emsp;&emsp;Update the dicscriminator by ascending its stochastic gradient:</p>
<script type="math/tex; mode=display">
\bigtriangledown_{\theta d}\frac{1}{m}\sum\limits_{i=1}^{m}[logD(\mathbf{x}^{i})+log(1-D(G(\mathbf{z}^{i})))]</script><p>&emsp;&emsp;<strong>end for</strong><br>&emsp;sample minibatch of m noise samples {z<sup>(1)</sup>, …, z<sup>(m)</sup>} from noise prior $p_g(\mathbf{z})$<br>&emsp;Update the generator by descending tis stochastic gradiant</p>
<script type="math/tex; mode=display">
\bigtriangledown_{\theta g}\frac{1}{m}\sum\limits_{i=1}^{m}log(1-D(G(\mathbf{z}^{i})))</script><p><strong>end for</strong></p>
<hr>
<h2 id="Global-Optimality-of-pg-pdata"><a href="#Global-Optimality-of-pg-pdata" class="headerlink" title="Global Optimality of pg=pdata"></a>Global Optimality of p<sub>g</sub>=p<sub>data</sub></h2><h3 id="Conclution-1"><a href="#Conclution-1" class="headerlink" title="Conclution 1"></a>Conclution 1</h3><p>For G fixed, the optimal discriminator D is</p>
<script type="math/tex; mode=display">
D_{G}^{*}(\boldsymbol{x})=\frac{p_{\text {data }}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}</script><h3 id="Theorem-1"><a href="#Theorem-1" class="headerlink" title="Theorem 1"></a>Theorem 1</h3><p>The global minimum of the virtual training criterion C(G) is achieved if and only if $p<em>g = p</em>{data}$. At that point, C(G) achieves the value − log 4.</p>
<h3 id="Proposition-2"><a href="#Proposition-2" class="headerlink" title="Proposition 2"></a>Proposition 2</h3><p>If G and D have enough capacity, and at each step of Algorithm 1, the discriminator is allowed to reach its optimum given G, and pg is updated so as to improve the criterion</p>
<script type="math/tex; mode=display">
\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right]</script><p>then $p_g$ converges to $p_data$</p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><ul>
<li>Generator: Mixture of rectifier linear activations and sigmoid activations</li>
<li>Discriminator: maxout activations + <strong>Dropout</strong></li>
</ul>
<p>Original address: <a href="https://arxiv.org/abs/1511.06434v1">GAN</a></p>
]]></content>
      <categories>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>GAN</tag>
        <tag>Aritcle</tag>
      </tags>
  </entry>
  <entry>
    <title>蛋白配体互作</title>
    <url>/2022/06/28/LigandProteinInteraction/</url>
    <content><![CDATA[<blockquote>
<p>本文以AP和LDHB_MOUSE互作为例，进行说明<br><span id="more"></span></p>
</blockquote>
<h2 id="软件配置"><a href="#软件配置" class="headerlink" title="软件配置"></a>软件配置</h2><h3 id="Autodock"><a href="#Autodock" class="headerlink" title="Autodock"></a>Autodock</h3><p><a href="https://zhuanlan.zhihu.com/p/148773006">AutoDock软件的安装（Windows）</a><br>注意：必须要把Autogrid.exe，Autodock.exe，adt.bat，proten.pdb，ligand.mol2(pdb)几个文件放在同一路径下。</p>
<h3 id="PyMol"><a href="#PyMol" class="headerlink" title="PyMol"></a>PyMol</h3><p>PyMol因为配置起来比较繁琐，而且它依赖的Python环境可能会和AutoDock冲突，因此推荐使用Anaconda安装，或者直接放包就行</p>
<h2 id="文件准备"><a href="#文件准备" class="headerlink" title="文件准备"></a>文件准备</h2><p>从UnitPro和Pubchem中下载蛋白和配体结构文件，这里UnitPro中找到的LDHB_MOUSE只能找到他的Alphafold2预测结构，但是可信度较高，故选用其pdb文件.</p>
<h3 id="小分子配体"><a href="#小分子配体" class="headerlink" title="小分子配体"></a>小分子配体</h3><p>小分子在Pubchem上搜索，并在3D Conformer中下载SDF文件<br><img src="https://s1.ax1x.com/2022/06/28/jZ7xVx.png" alt="小分子"></p>
<h3 id="蛋白PDB文件"><a href="#蛋白PDB文件" class="headerlink" title="蛋白PDB文件"></a>蛋白PDB文件</h3><p>可在PDB或者在UnitPro中下载<br><img src="https://s1.ax1x.com/2022/06/28/jZ7za6.png" alt="蛋白质"></p>
<h3 id="小分子文件转换"><a href="#小分子文件转换" class="headerlink" title="小分子文件转换"></a>小分子文件转换</h3><p>因为AutoDock不支持.sdf文件，因此需要用mglTools文件夹（见AutoDock安装）中openbabel文件夹下的obgui.exe<br>将.sdf文件转换为.pdb文件，记得加后缀。<br><img src="https://s1.ax1x.com/2022/06/28/jZ7jq1.png" alt="转换"></p>
<h2 id="结构预处理和对接"><a href="#结构预处理和对接" class="headerlink" title="结构预处理和对接"></a>结构预处理和对接</h2><p>参考链接：<br><a href="https://blog.csdn.net/weixin_42655515/article/details/113706512?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-113706512-blog-113706508.pc_relevant_multi_platform_whitelistv1&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-113706512-blog-113706508.pc_relevant_multi_platform_whitelistv1&amp;utm_relevant_index=1">蛋白受体文件的预处理</a><br><a href="https://blog.csdn.net/weixin_42655515/article/details/113706511?spm=1001.2101.3001.6650.2&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2-113706511-blog-113706508.pc_relevant_multi_platform_whitelistv1&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2-113706511-blog-113706508.pc_relevant_multi_platform_whitelistv1&amp;utm_relevant_index=5">配体小分子的预处理</a><br><a href="https://blog.csdn.net/weixin_42655515/article/details/113706514">AutoDock对接操作与对接结果解读</a><br>以上三步获得结果文件后，可以在AutoDock中进行初步的可视化和氢键的观察<br><a href="https://blog.csdn.net/weixin_42655515/article/details/113706514">AutoDock对接操作与对接结果解读</a></p>
<p>PyMol可视化</p>
<ol>
<li>用OpenBabel将result.pdbqt转化为result.pdb，步骤同上，最后用PyMol打开</li>
<li>先选中小分子，使其在右侧栏显示出来，随后将蛋白质以Surface方式显示，小分子以Stick方式显示即可。</li>
</ol>
]]></content>
      <categories>
        <category>生信</category>
      </categories>
      <tags>
        <tag>生信</tag>
        <tag>分子互作</tag>
      </tags>
  </entry>
  <entry>
    <title>MMCore配置</title>
    <url>/2022/02/28/MMCore%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="MMCore配置（Windows）"><a href="#MMCore配置（Windows）" class="headerlink" title="MMCore配置（Windows）"></a>MMCore配置（Windows）</h1><ol>
<li>下载<a href="https://micro-manager.org/Download_Micro-Manager_Latest_Release">Micro-Manager GUI</a></li>
<li>根据<a href="https://github.com/micro-manager/pymmcore">pymmcore github</a>主页中的信息创建虚拟环境<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">python -m pip <span class="keyword">install</span> pymmcore</span><br></pre></td></tr></table></figure>
基本上第一次install会失败，再install一次就没问题了</li>
</ol>
]]></content>
      <categories>
        <category>MMCore</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>MMCore</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt5入门&amp;简介</title>
    <url>/2021/08/14/Qt-1/</url>
    <content><![CDATA[<h1 id="入门导航-amp-简介"><a href="#入门导航-amp-简介" class="headerlink" title="入门导航&amp;简介"></a>入门导航&amp;简介</h1><blockquote>
<p>写UI需求（实际上是想要给自己写一个桌面宠物/老婆），结合博客导航（天山老妖S原创）和书籍学习。以下为博客导航，书籍学习则希望参考 《PyQt5快速开发与实战》。<br><span id="more"></span></p>
</blockquote>
<h2 id="入门导航"><a href="#入门导航" class="headerlink" title="入门导航"></a>入门导航</h2><ul>
<li><a href="https://blog.51cto.com/9291927/2422184">PyQt5简介</a></li>
<li><a href="https://blog.51cto.com/9291927/2422187">PyQt5信号槽机制</a></li>
<li><a href="https://blog.51cto.com/9291927/2422601">PyQt5基本窗口组件</a></li>
<li><a href="https://blog.51cto.com/9291927/2423254">PyQt5高级窗口组件</a></li>
<li><a href="https://blog.51cto.com/9291927/2423303">PyQt5布局管理</a></li>
<li><a href="https://blog.51cto.com/9291927/2424153">PyQt5 GUI界面设计</a></li>
<li><a href="https://blog.51cto.com/9291927/2424319">PyQt5 扩展</a></li>
<li><a href="https://blog.51cto.com/9291927/2424320">PyQt5 数据库操作</a></li>
</ul>
<h2 id="PyQt5简介"><a href="#PyQt5简介" class="headerlink" title="PyQt5简介"></a>PyQt5简介</h2><h3 id="PyQt5简单介绍"><a href="#PyQt5简单介绍" class="headerlink" title="PyQt5简单介绍"></a>PyQt5简单介绍</h3><blockquote>
<p>PyQt是Qt框架的Python实现，是最强的GUI库之一。PyQt提供了一个设计良好的<strong>窗口控件组合</strong>，每一个PyQt空间都对应一个Qt控件，因此PyQt的API接口和Qt的API接口很接近。</p>
</blockquote>
<p>官方网站：www.riverbankcomputing.com<br>PyQt5提供GPL版和商业版证书，自由开发者可以使用免费的GPL许可，如果需要将PyQt用于商业应用，则必须购买商业许可。</p>
<ul>
<li>Qt框架：Qt是一个1991年由Qt Company开发的跨平台C++图形用户界面应用程序开发框架，可以开发GUI程序，也可开发非GUI程序，如控制台和服务器。是一种面向对象的框架</li>
<li>GUI：图形界面</li>
<li>API，英文全称Application Programming Interface，翻译为“应用程序编程接口”。 是一些预先定义的函数，目的是提供应用程序与开发人员基于某软件或硬件得以访问一组例程的能力，而又无需访问源码，或理解内部工作机制的细节</li>
</ul>
<h3 id="PyQt5的特性"><a href="#PyQt5的特性" class="headerlink" title="PyQt5的特性"></a>PyQt5的特性</h3><ol>
<li>基于高性能Qt的GUI控件集</li>
<li><u>能够跨平台运行在Linux，Window和Mac OS系统上</u></li>
<li>使用<strong>信号槽</strong>机制进行通信</li>
<li>对Qt库完全封装</li>
<li>可以使用成熟的IDE进行界面设计，并自动生成可执行的Python代码</li>
<li>提供一整套种类齐全的窗口控件</li>
</ol>
<h3 id="PyQt4与PyQt5的区别"><a href="#PyQt4与PyQt5的区别" class="headerlink" title="PyQt4与PyQt5的区别"></a>PyQt4与PyQt5的区别</h3><p>区别如下</p>
<ol>
<li>重新组合模块，PyQt4中的某些模块被废弃（QtScript），有些被拆分为两个子模块（QtGui、QtWebKit）</li>
<li>添加新模块，如QtBluetooth、Q他Positioning和Enginio</li>
<li>废弃SINGAL()和SLOT()，用新的<strong>信号槽</strong>处理方式</li>
<li>不再支持所有被标记为废弃的或者不建议使用的Qt API</li>
</ol>
<h3 id="PyQt5模块"><a href="#PyQt5模块" class="headerlink" title="PyQt5模块"></a>PyQt5模块</h3><p>主要模块如下</p>
<ol>
<li>QtCore包含非核心的非GUI功能，主要与时间、文件、文件夹、各种数据、流、URLs、mime类文件文件、 进程、线程一起使用</li>
<li>QtGui包括窗口系统、事件处理、2D图像、·基本绘画、字体和文字类</li>
<li>QtWidgets包含一系列创建桌面应用的UI元素</li>
<li>QtBluetooth模块包含<strong>查找</strong>和<strong>连接蓝牙</strong>的类</li>
<li>QtNetwork包含网络编程的类，能让TCP/IP和UDP开发变得更加方便和可靠</li>
<li>QtPositioning包含定位的类，可以使用卫星、WiFi甚至<strong>文本</strong></li>
<li>Engine包含通过客户端进入和管理Qt Cloud的类</li>
<li>QtWebSockets包含WebSocket协议的类</li>
<li>QtWebKit包含一个基WebKit2的web浏览器</li>
<li>QtWebKitWidgets包含基于QtWidgets的WebKit1类</li>
<li>QtXml包含<strong>处理xml的类</strong>，提供SAX和DOM API的工具</li>
<li>QtSvg提供显示SVG内容的类，Scalable Vector Graphics(SVG)是一种是一种基于可扩展标记语言(XML)，用于描述<strong>二维矢量图形</strong>的图形格式</li>
<li>QtSql提供处理数据库的工具</li>
<li>QtTest提供测试PyQt5应用的工具</li>
</ol>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PyQt5 <span class="keyword">import</span> QtWidgets, QtCore</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QtWidgets.QApplication(sys.argv)</span><br><span class="line">    widget = QtWidgets.QWidget()</span><br><span class="line">    widget.resize(<span class="number">800</span>, <span class="number">600</span>)</span><br><span class="line">    widget.setWindowTitle(<span class="string">&quot;Hello, PyQt5&quot;</span>)</span><br><span class="line">    widget.show()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p>运行结果如下</p>
<p><img src="http://fang-bnn.gitee.io/image_bed/bed/Qt%E7%AE%80%E4%BB%8B.png" alt="运行结果"></p>
]]></content>
      <categories>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title>PyQt5信号槽机制(一)</title>
    <url>/2021/08/15/Qt-2/</url>
    <content><![CDATA[<h1 id="PyQt5信号槽机制-一"><a href="#PyQt5信号槽机制-一" class="headerlink" title="PyQt5信号槽机制(一)"></a>PyQt5信号槽机制(一)</h1><blockquote>
<p>信号槽是Qt的核心机制，也是PyQt中编程的通信机制，在Qt中，QObject对象和PyQt中所有继承自QWidget的控件都支持信号机制。当信号发射时，连接的<strong>槽函数</strong>会自动执行。在PyQt5中，信号和槽函数通过<code>object.signal.connect()</code>方法进行连接。<br><span id="more"></span></p>
</blockquote>
<h2 id="信号槽（slot）简介"><a href="#信号槽（slot）简介" class="headerlink" title="信号槽（slot）简介"></a>信号槽（slot）简介</h2><p>信号槽特点如下：</p>
<ol>
<li>一个信号可以连接多个槽</li>
<li>一个信号可以连接另一个信号</li>
<li>信号参数可以是任意Python类型</li>
<li>一个槽可以监听任意多个信号</li>
<li>信号与槽之间的连接方式可以是同步连接，也可以是异步连接</li>
<li>信号与槽的连接可以跨线程</li>
<li>信号可以断开<br>在编写一个类的时候，要首先定义类的<strong>信号和槽</strong>，在类的信号与槽进行连接，实现对象之间的数据传输。当事件或状态发生改变时，会发出信号，进而出发<strong>执行事件</strong>或信号相关联的<strong>槽函数</strong><br><img src="http://fang-bnn.gitee.io/image_bed/bed/%E6%A7%BD%E4%BF%A1%E5%8F%B7.png" alt="槽信号"></li>
</ol>
<h3 id="定义信号"><a href="#定义信号" class="headerlink" title="定义信号"></a>定义信号</h3><p>PyQt内置信号是自动定义的，使用<code>PyQt5.QtCore.pyqtSignal</code>函数可以为QObject对象创建一个信号，使用pyqtSignal函数可以把信号定义为类的属性。pyqtSignal的原型如下<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">pyqtSignal</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *types, name: <span class="built_in">str</span>= ...</span>) -&gt; <span class="keyword">None</span>:</span> ...</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>type</code>：表示定义信号时参数的类型</li>
<li><code>name</code>：表示信号的名称，默认使用<strong>类的属性名称</strong><br>使用<code>pyqtSignal</code>函数创建一个或多个重载的未绑定的信号作为类的属性，信号只能在<code>QObject</code>的子类中定义。信号必须在类创建时定义，<strong>不能在类创建后作为类的属性动态添加进来</strong>。使用pyqtSignal函数定义信号时，信号可以传递多各参数，并指定信号传递参数的类型，参数类型是标准的Python数据类型，包括<strong>字符串、日期、布尔类型、数字、列表、字典、元组</strong>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PyQt5.QtCore <span class="keyword">import</span> pyqtSignal, QObject</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StandardItem</span>(<span class="params">QObject</span>):</span></span><br><span class="line">    data_changed = pyqtSignal(<span class="built_in">str</span>, <span class="built_in">str</span>, name=<span class="string">&#x27;dataChanged&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.dataChanged.emit(<span class="string">&quot;old status&quot;</span>,<span class="string">&quot;new status&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="操作信号"><a href="#操作信号" class="headerlink" title="操作信号"></a>操作信号</h3><ul>
<li><code>connect</code>函数：将信号绑定到槽函数上，<code>QObject.signal.connect(self, slot, type=None, no_receiver_check=False)</code></li>
<li><code>disconnect</code>函数：将信号解绑，<code>QObject.signal.disconnect(self, slot=None)</code></li>
<li><code>emit</code>函数：发射信号，<code>emit(self, *args)</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PyQt5.QtCore <span class="keyword">import</span> pyqtSignal, QObject</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StandardItem</span>(<span class="params">QObject</span>):</span></span><br><span class="line">    data_changed = pyqtSignal(<span class="built_in">str</span>, <span class="built_in">str</span>, name=<span class="string">&#x27;dataChanged&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.dataChanged.emit(<span class="string">&quot;old status&quot;</span>,<span class="string">&quot;new status&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 槽函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onDataChanged</span>(<span class="params">self, old, new</span>):</span></span><br><span class="line">        print(old)</span><br><span class="line">        print(new)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = QCoreApplication(sys.argv)</span><br><span class="line">    item = StandardItem()</span><br><span class="line">    item.dataChanged.connect(item.onDataChanged)</span><br><span class="line">    item.update()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br><span class="line"></span><br><span class="line"><span class="comment">###############</span></span><br><span class="line"><span class="comment">#####OUTPUT####</span></span><br><span class="line"><span class="comment">###############</span></span><br><span class="line"><span class="comment"># old status</span></span><br><span class="line"><span class="comment"># new status</span></span><br></pre></td></tr></table></figure>
<h2 id="信号槽与应用"><a href="#信号槽与应用" class="headerlink" title="信号槽与应用"></a>信号槽与应用</h2><h3 id="内置信号与自定义槽函数"><a href="#内置信号与自定义槽函数" class="headerlink" title="内置信号与自定义槽函数"></a>内置信号与自定义槽函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QWidget, QApplication, QPushButton</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainWindow</span>(<span class="params">QWidget</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line">        self.setWindowTitle(<span class="string">&quot;MainWindow Demo&quot;</span>)</span><br><span class="line">        self.resize(<span class="number">800</span>, <span class="number">600</span>)</span><br><span class="line"></span><br><span class="line">        button = QPushButton(<span class="string">&quot;close&quot;</span>, self)</span><br><span class="line">        <span class="comment"># 连接内置信号与自定义槽</span></span><br><span class="line">        button.clicked.connect(self.onClose)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自定义槽函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onClose</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    window = MainWindow()</span><br><span class="line">    window.show()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p>这里，<code>button.click()</code>就是一个内置信号，他与onClose槽函数连接。而用户按下的动作即为发射。点击按钮时触发按钮内置的clicked信号，执行绑定的自定义槽函数onClose。</p>
<h3 id="自定义信号和内置槽函数"><a href="#自定义信号和内置槽函数" class="headerlink" title="自定义信号和内置槽函数"></a>自定义信号和内置槽函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtCore <span class="keyword">import</span> pyqtSignal</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QWidget, QApplication, QPushButton</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainWindow</span>(<span class="params">QWidget</span>):</span></span><br><span class="line">    closeSignal = pyqtSignal()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line">        self.setWindowTitle(<span class="string">&quot;MainWindow Demo&quot;</span>)</span><br><span class="line">        self.resize(<span class="number">800</span>, <span class="number">600</span>)</span><br><span class="line"></span><br><span class="line">        button = QPushButton(<span class="string">&quot;close&quot;</span>, self)</span><br><span class="line">        <span class="comment"># 连接内置信号与自定义槽</span></span><br><span class="line">        button.clicked.connect(self.onClose)</span><br><span class="line">        <span class="comment"># 连接自定义信号closeSignal与内置槽函数close</span></span><br><span class="line">        self.closeSignal.connect(self.close)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自定义槽函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onClose</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 发送自定义信号</span></span><br><span class="line">        self.closeSignal.emit()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    window = MainWindow()</span><br><span class="line">    window.show()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p>通过<strong>内置信号</strong><code>click</code>连接到<strong>自定义槽函数</strong>，槽函数中触发<strong>自定义信号</strong>的发射，从而触发<strong>内置槽函数</strong><code>QWidget.close()</code>函数</p>
<h3 id="自定义信号和自定义槽函数"><a href="#自定义信号和自定义槽函数" class="headerlink" title="自定义信号和自定义槽函数"></a>自定义信号和自定义槽函数</h3><p>结合上述两种方法，大同小异</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtCore <span class="keyword">import</span> pyqtSignal</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QWidget, QApplication, QPushButton</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainWindow</span>(<span class="params">QWidget</span>):</span></span><br><span class="line">    closeSignal = pyqtSignal()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line">        self.setWindowTitle(<span class="string">&quot;MainWindow Demo&quot;</span>)</span><br><span class="line">        self.resize(<span class="number">800</span>, <span class="number">600</span>)</span><br><span class="line"></span><br><span class="line">        button = QPushButton(<span class="string">&quot;close&quot;</span>, self)</span><br><span class="line">        <span class="comment"># 连接内置信号与自定义槽</span></span><br><span class="line">        button.clicked.connect(self.onClicked)</span><br><span class="line">        <span class="comment"># 连接自定义信号closeSignal与内置槽函数close</span></span><br><span class="line">        self.closeSignal.connect(self.onClose)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自定义槽函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onClicked</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 发送自定义信号</span></span><br><span class="line">        self.closeSignal.emit()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自定义槽函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onClose</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    window = MainWindow()</span><br><span class="line">    window.show()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p>参考自:<br><a href="https://blog.51cto.com/u_9291927/2422187">PyQt5快速入门（二）PyQt5信号槽机制</a></p>
]]></content>
      <categories>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch</title>
    <url>/2021/09/14/Pytorch/</url>
    <content><![CDATA[<h1 id="Snippets-for-Pytorch"><a href="#Snippets-for-Pytorch" class="headerlink" title="Snippets for Pytorch"></a>Snippets for Pytorch</h1><blockquote>
<p>新手码代码时不会之处，资料源于各个博客，参考链接位于最下方</p>
</blockquote>
<span id="more"></span>
<h1 id="数据集相关"><a href="#数据集相关" class="headerlink" title="数据集相关"></a>数据集相关</h1><h2 id="torch-utils-data-DataLoader"><a href="#torch-utils-data-DataLoader" class="headerlink" title="torch.utils.data.DataLoader"></a>torch.utils.data.DataLoader</h2><ul>
<li><code>DataLoader</code>是一种可迭代对象，使用<code>iter()</code>访问，不能使用<code>next()</code>访问，通过<code>iter()</code>构建<a href="https://www.runoob.com/python3/python3-iterator-generator.html">迭代器</a>，然后可以使用<code>next()</code>访问</li>
<li>和其他迭代对象一样，<code>DataLoader</code>也可以用<code>for</code>访问，并且一般用<code>for X, y in DataLoader:</code>进行可迭代对象的访问。</li>
<li><code>DataLoader</code>本质上是一个<code>iterable</code>，并利用多进程来加速<code>batch data</code>的处理，使用<code>yield</code>来使用有限的内存。</li>
<li><code>DataLoader</code>是一个高效，简洁，只管的网络输入数据结构，便于使用和扩展。</li>
</ul>
<h3 id="pytorch数据加载流程"><a href="#pytorch数据加载流程" class="headerlink" title="pytorch数据加载流程"></a>pytorch数据加载流程</h3><ol>
<li>创建一个Dataset对象</li>
<li>创建一个DataLoader对象</li>
<li>循环这个DataLoader对象，将 img，label加载到模型中训练<br>伪代码如下（不严格遵守pytorch语法）</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset = MyDataset(transform=trans)</span><br><span class="line">dataloader = pytorch.utils.data.DataLoader(dataset)</span><br><span class="line">num_epochs = get(<span class="string">&#x27;n_epochs&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">	<span class="keyword">for</span> X, y <span class="keyword">in</span> dataloader:</span><br><span class="line">		<span class="comment"># Load Data in Models</span></span><br></pre></td></tr></table></figure>
<h3 id="DataLoader详解"><a href="#DataLoader详解" class="headerlink" title="DataLoader详解"></a>DataLoader详解</h3><p><strong>DataLoader的作用</strong>：将自定义的Datset根据<code>batchsize</code>的大小，是否<code>shuffle</code>等封装成一个<code>batchsize</code>大小的<code>tensor</code>，用于后续的训练。<br><code>DataLoader(object)</code>的参数：</p>
<ul>
<li>dataset(Dataset): 传入的数据集</li>
<li>batch_size(int, optional): 每个batch有多少个样本</li>
<li>shuffle(bool, optional): 在每个epoch开始的时候，对数据进行重新排序</li>
<li>sampler(Sampler, optional): 自定义从数据集中取样本的策略，如果指定这个参数，那么shuffle必须为False</li>
<li>batch_sampler(Sampler, optional): 与sampler类似，但是一次只返回一个batch的indices（索引），需要注意的是，一旦指定了这个参数，那么batch_size,shuffle,sampler,drop_last就不能再制定了（互斥——Mutually exclusive）</li>
<li>num_workers (int, optional): 这个参数决定了有几个进程来处理data loading。0意味着所有的数据都会被load进主进程。（默认为0）</li>
<li>collate_fn (callable, optional): 将一个list的sample组成一个mini-batch的函数</li>
<li>pin_memory (bool, optional)： 如果设置为True，那么data loader将会在返回它们之前，将tensors拷贝到CUDA中的固定内存（CUDA pinned memory）中.</li>
<li>drop_last (bool, optional): 如果设置为True：这个是对最后的未完成的batch来说的，比如你的batch_size设置为64，而一个epoch只有100个样本，那么训练的时候后面的36个就被扔掉了；如果为False（默认），那么会继续正常执行，只是最后的batch_size会小一点。</li>
<li>timeout(numeric, optional): 如果是正数，表明等待从worker进程中收集一个batch等待的时间，若超出设定的时间还没有收集到，那就不收集这个内容了。这个numeric应总是大于等于0。默认为0</li>
<li>worker_init_fn (callable, optional): 每个worker初始化函数 If not None, this will be called on each worker subprocess with the worker id (an int in [0, num_workers - 1]) as input, after seeding and before data loading. (default: None)</li>
</ul>
<p>一般重要的参数有：<code>dataset</code>, <code>batch_size</code>, <code>shuffle</code>, <code>num_workers</code>, <code>drop_last</code></p>
<p><a href="https://www.cnblogs.com/ranjiewen/p/10128046.html">DataLoader参考</a></p>
<h2 id="自定义数据集"><a href="#自定义数据集" class="headerlink" title="自定义数据集"></a>自定义数据集</h2><ul>
<li>自定义的数据集必须继承自<code>torch.utils.data.Dataset</code>。<code>torch.utils.data.Dataset</code>这个类是一个表示数据集的抽象类，负责处理索引(index)到样本(sample)映射的一个类(class)。Pytorch提供两种数据集： <strong>Map式数据集</strong> 和 <strong>Iterable式数据集</strong>。这里我们只介绍前者</li>
<li>自定义的数据集中必须包含以下两种方法：<code>__getitem__</code>和<code>__len__</code>。其中<code>__getitem__</code>用于获取索引对应的样本，<code>__len__</code>方法用于获取样本长度。</li>
<li>接下来提供构建的范式</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span>(<span class="params">torch.utils.data.Dataset</span>):</span></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, file_path, transform, unaligned</span>):</span></span><br><span class="line">		<span class="comment">#<span class="doctag">TODO:</span> 加载各项参数，包括数据集路径，变换，是否通过index检索</span></span><br><span class="line">		self.file_path = file_path</span><br><span class="line">		self.transform = transform</span><br><span class="line">		self.unaligned = unaligned</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">		item = self.file_path[index]</span><br><span class="line">		item = self.transform(item)</span><br><span class="line">		<span class="keyword">return</span> item</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">		<span class="keyword">return</span> <span class="built_in">len</span>(self.file_path)</span><br></pre></td></tr></table></figure>
<h1 id="训练过程相关"><a href="#训练过程相关" class="headerlink" title="训练过程相关"></a>训练过程相关</h1><h2 id="初始化：Model-apply-Initial"><a href="#初始化：Model-apply-Initial" class="headerlink" title="初始化：Model.apply(Initial)"></a>初始化：<code>Model.apply(Initial)</code></h2><h3 id="为什么要初始化？"><a href="#为什么要初始化？" class="headerlink" title="为什么要初始化？"></a>为什么要初始化？</h3><ol>
<li>加快梯度下降的收敛速度</li>
<li>更有可能获得一个低模型误差，或者低泛化误差的模型</li>
<li>降低因为未初始化或初始化不当导致的梯度消失或者梯度爆炸问题。此情况会导致模型训练速度变慢，崩溃，甚至失败（如全连接层中，如果$W_{ij}$的每一个参数都很大，用Sigmoid作为激活函数，则会导致梯度消失）</li>
<li>随机初始化，可以打破对成性，从而保证不同的隐藏单元可以学习到不同的东西。</li>
</ol>
<h3 id="如何初始化"><a href="#如何初始化" class="headerlink" title="如何初始化"></a>如何初始化</h3><ol>
<li>预训练初始化</li>
<li>全0初始化（线性回归，Logistics回归）</li>
<li>固定值初始化<ul>
<li>BN层，$\gamma$为1，$\beta$为0</li>
<li>Bias通常用0初始化，对于ReLU激活的神经元，通常采用0.01偏置</li>
</ul>
</li>
<li>固定方差初始化<ul>
<li>高斯分布</li>
<li>均匀分布</li>
</ul>
</li>
<li>方差放缩初始化<ul>
<li>Xavier初始化（ReLU较差）</li>
<li>He初始化</li>
</ul>
</li>
</ol>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><ul>
<li><code>weights_init_normal</code>函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights_init_normal</span>(<span class="params">m</span>):</span></span><br><span class="line"></span><br><span class="line">    classname = m.__class__.__name__</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> classname.find(<span class="string">&#x27;Conv&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">        torch.nn.init.kaiming_normal_(m.weight.data, a=<span class="number">0.01</span>, mode=<span class="string">&#x27;fan_in&#x27;</span>, nonlinearity=<span class="string">&#x27;leaky_relu&#x27;</span>)</span><br><span class="line">        <span class="comment">#print(m.__class__.__name__, m.weight, m.bias)</span></span><br><span class="line">    <span class="keyword">elif</span> classname.find(<span class="string">&#x27;BatchNorm2d&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">        torch.nn.init.constant(m.weight.data, <span class="number">1.0</span>)</span><br><span class="line">        torch.nn.init.constant(m.bias.data, <span class="number">0.0</span>)</span><br><span class="line">        <span class="comment">#print(m.__class__.__name__,m.weight, m.bias)</span></span><br></pre></td></tr></table></figure>
<ul>
<li>训练初始化</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.apply(weights_init_normal)</span><br></pre></td></tr></table></figure>
<h1 id="模型验证相关"><a href="#模型验证相关" class="headerlink" title="模型验证相关"></a>模型验证相关</h1><h2 id="一些基本概念"><a href="#一些基本概念" class="headerlink" title="一些基本概念"></a>一些基本概念</h2><ul>
<li>在正向传播时，需要求导的变量除了执行<code>forward()</code>之外，还会同时为反向传播做一些准备</li>
<li>叶子节点：当一个tensor是<strong>用户创建</strong>时(即用<code>torch.tensor()</code>等函数定义的，而非通过计算获得的)，他是一个叶子节点，当tensor时由其他运算操作产生时，不是叶子节点</li>
<li>在<code>backward()</code>之后只有叶子节点相关的导数结果会被保存，而非叶子节点的导数结果会被抛弃（为了减小内存消耗）</li>
</ul>
<h2 id="中间层检验：hook"><a href="#中间层检验：hook" class="headerlink" title="中间层检验：hook"></a>中间层检验：<code>hook</code></h2><p>在对训练结果进行评判时，我们往往需要对网络的中间结果进行评估从而判断网络的注意力和权重分配等效果，通常有<strong>卷积核</strong>、特征图、梯度等。卷积核较后二者容易获得，但是特征图一经传递完成就会释放内存从而防止内存冗余，梯度方面，只保存节点梯度。在模型中增加中间结果保存操作可以实现中间结果的，但是会导致速度变慢、操作复杂、训练中产生大量数据等问题。所以需要用其他方法，而<code>hook</code>则是pytorch提供的一个较好的方法。包括以下函数：<code>Tensor.register_hook(hook_fn)</code>,<code>nn.Module.register_forward_hook(hook_fn)</code>,<code>nn.Module.register_backward_hook(hook_fn)</code></p>
<h3 id="Tensor-register-hook-hook-fn"><a href="#Tensor-register-hook-hook-fn" class="headerlink" title="Tensor.register_hook(hook_fn)"></a><code>Tensor.register_hook(hook_fn)</code></h3><blockquote>
<p>功能：注册一个反向传播的hook函数，用于自动记录Tensor的梯度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>]).require_grad_()</span><br><span class="line">b = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>]).require_grad_()</span><br><span class="line">d = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>]).require_grad_()</span><br><span class="line">c = a + b</span><br><span class="line">e = c * d</span><br><span class="line">o = e.<span class="built_in">sum</span>()</span><br><span class="line">o.backward()</span><br></pre></td></tr></table></figure>
<p>以上代码中，只有a,b,d为叶子节点，因此只有他们的导数被保留，其他导数，如c，d，e，o无导数，<code>o.grad</code>返回为None。下面通过<code>register_hook</code>方法给cdeo等非叶子节点的张量保留导数。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hook_fn</span>(<span class="params">grad</span>):</span></span><br><span class="line">	print(grad)</span><br><span class="line">e.register_hook(hook_fn)</span><br><span class="line">o.backward()</span><br></pre></td></tr></table></figure><br>在对<code>o.backward()</code>时，自动执行张量<code>e</code>所关联的<code>hook_fn</code>，从而直接将<code>e</code>的导数打印出来</p>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><ol>
<li>在反向传播前，定义一个<code>hook</code>函数，描述对梯度的操作，函数名自拟（一般为<code>hook_fn(grad)</code>），参数只有grad，表示梯度；</li>
<li>对要获取梯度的张量进行<code>Tensor.register_hook(hook_fn)</code>注册</li>
<li>执行反向传播，执行的过程中自动调用<code>hook_fn</code>函数</li>
</ol>
</blockquote>
<h3 id="nn-Module-register-forward-hook-hook-fn-amp-nn-Module-register-backward-hook-hook-fn"><a href="#nn-Module-register-forward-hook-hook-fn-amp-nn-Module-register-backward-hook-hook-fn" class="headerlink" title="nn.Module.register_forward_hook(hook_fn)&amp;nn.Module.register_backward_hook(hook_fn)"></a><code>nn.Module.register_forward_hook(hook_fn)</code>&amp;<code>nn.Module.register_backward_hook(hook_fn)</code></h3><blockquote>
<p>这两个操作对象都是<code>nn.Module</code>类，如神经网络中的卷积层<code>nn.Conv2d</code>，全连接层<code>nn.Linear</code>等。</p>
</blockquote>
<p>对于模型的中间模块，也可以视作中间节点（非叶子节点），其输出为<strong>特征图</strong>或<strong>激活值</strong>，若要获取，则可以用hook功能</p>
<ul>
<li><code>register_forward_hook</code>是前向传播的输出的，即特征图或激活值，而<code>register_backward_hook</code>是反向传播输出的，即梯度值</li>
</ul>
<h4 id="register-forward-hook-hook-fn"><a href="#register-forward-hook-hook-fn" class="headerlink" title="register_forward_hook(hook_fn)"></a><code>register_forward_hook(hook_fn)</code></h4><p>对于hook_fn的定义如下<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_hook</span>(<span class="params">module, <span class="built_in">input</span>, output</span>):</span></span><br><span class="line">	operations</span><br></pre></td></tr></table></figure><br>module指的是模块，input指的是输入模块的内容，output指的是输出模块的内容。</p>
<h4 id="register-backward-hook-hook-fn"><a href="#register-backward-hook-hook-fn" class="headerlink" title="register_backward_hook(hook_fn)"></a><code>register_backward_hook(hook_fn)</code></h4><p>对于hook_fn的定义如下<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_hook</span>(<span class="params">module, grad_in, grad_out</span>):</span></span><br><span class="line">	operations</span><br></pre></td></tr></table></figure><br>值得注意的是这里的<code>grad_in</code>和<code>grad_out</code>，这里的in和out都是相对于forward传递而言的。如线性模块$o=W\times x+b$，<code>grad_out</code>指的就是o的梯度；而grad_in因为有三个变量，因此他是包含三个元素的tuple</p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>,<span class="number">6</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>,<span class="number">9</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        self.relu2 = nn.ReLU()</span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">8</span>*<span class="number">8</span>*<span class="number">9</span>, <span class="number">120</span>)</span><br><span class="line">        self.relu3 = nn.ReLU()</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.pool1(self.relu1(self.conv1(x)))</span><br><span class="line">        out = self.pool2(self.relu2(self.conv2(out)))</span><br><span class="line">        out = out.view(out.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        out = self.relu3(self.fc1(out))</span><br><span class="line">        out = self.fc2(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward_hook</span>(<span class="params">module, grad_in, grad_out</span>):</span></span><br><span class="line">    grad_block[<span class="string">&#x27;grad_in&#x27;</span>] = grad_in</span><br><span class="line">    grad_block[<span class="string">&#x27;grad_out&#x27;</span>] = grad_out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">farward_hook</span>(<span class="params">module, inp, outp</span>):</span></span><br><span class="line">    fmap_block[<span class="string">&#x27;input&#x27;</span>] = inp</span><br><span class="line">    fmap_block[<span class="string">&#x27;output&#x27;</span>] = outp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loss_func = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成一个假标签以便演示</span></span><br><span class="line">label = torch.empty(<span class="number">1</span>, dtype=torch.long).random_(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成一副假图像以便演示</span></span><br><span class="line">input_img = torch.randn(<span class="number">1</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>).requires_grad_()  </span><br><span class="line"></span><br><span class="line">fmap_block = <span class="built_in">dict</span>()  <span class="comment"># 装feature map</span></span><br><span class="line">grad_block = <span class="built_in">dict</span>()  <span class="comment"># 装梯度</span></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注册hook</span></span><br><span class="line">net.conv2.register_forward_hook(farward_hook)</span><br><span class="line">net.conv2.register_backward_hook(backward_hook)</span><br><span class="line"></span><br><span class="line">outs = net(input_img)</span><br><span class="line">loss = loss_func(outs, label)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;End.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>参考网站：<a href="https://www.jianshu.com/p/69e57e3526b3">PyTorch之HOOK——获取神经网络特征和梯度的有效工具</a></p>
]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>Python</tag>
        <tag>Coding</tag>
      </tags>
  </entry>
  <entry>
    <title>PyQt5信号槽机制(二)</title>
    <url>/2021/08/16/Qt-3/</url>
    <content><![CDATA[<h1 id="PyQt5信号槽机制-二"><a href="#PyQt5信号槽机制-二" class="headerlink" title="PyQt5信号槽机制(二)"></a>PyQt5信号槽机制(二)</h1><blockquote>
<p>继PyQt5信号槽机制1</p>
</blockquote>
<span id="more"></span>
<h2 id="信号槽应用进阶"><a href="#信号槽应用进阶" class="headerlink" title="信号槽应用进阶"></a>信号槽应用进阶</h2><h3 id="自定义信号槽"><a href="#自定义信号槽" class="headerlink" title="自定义信号槽"></a>自定义信号槽</h3><p>通常通过类变量自定义信号对象，<span style='background: green'>在<code>__init__</code>函数前自定义信号</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyQtObject</span>(<span class="params">QObject</span>):</span></span><br><span class="line">    noParameterSignal = pyqtSignal()</span><br><span class="line">    oneParameterSignal = pyqtSignal(<span class="built_in">int</span>)</span><br><span class="line">    <span class="comment"># 定义一个参数的重载版本的信号，参数类型可以为int或str</span></span><br><span class="line">    oneParameterOverloadSignal = pyqtSignal([<span class="built_in">int</span>], [<span class="built_in">str</span>])</span><br><span class="line">    <span class="comment"># 定义两个个参数的重载版本的信号，参数类型可以为int,str或int,int</span></span><br><span class="line">    twoParameterOverloadSignal = pyqtSignal([<span class="built_in">int</span>, <span class="built_in">str</span>], [<span class="built_in">int</span>, <span class="built_in">int</span>])</span><br><span class="line">    oneParameterSignalList = pyqtSignal(<span class="built_in">list</span>)</span><br><span class="line">    oneParameterSignalDict = pyqtSignal(<span class="built_in">dict</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 无参的槽函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onNoParameterSlot</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;no parameter signal&quot;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onOneParameterSlot</span>(<span class="params">self, nIndex</span>):</span></span><br><span class="line">        print(<span class="string">&quot;one parameter signal: &quot;</span>, nIndex)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onTwoParameterSlot</span>(<span class="params">self, nIndex, status</span>):</span></span><br><span class="line">        print(<span class="string">&quot;two parameter signal:&quot;</span>, nIndex, status)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.noParameterSignal.emit()</span><br><span class="line">        self.oneParameterSignal.emit()</span><br><span class="line">        self.twoParameterOverloadSignal.emit()</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    MyQtObj = MyQtObject()</span><br><span class="line">    MyQtObj.noParameterSignal.connect(onNoParameterSlot)</span><br><span class="line">    MyQtObj.oneParameterSignal.connect(onOneParameterSlot)</span><br><span class="line">    MyQtObj.twoParameterOverloadSignal(onTwoParameterSlot)</span><br><span class="line">    </span><br><span class="line">    MyQtObj.update()</span><br></pre></td></tr></table></figure>
<h3 id="信号槽传递自定义参数"><a href="#信号槽传递自定义参数" class="headerlink" title="信号槽传递自定义参数"></a>信号槽传递自定义参数</h3><p>Qt中信号个数必须大于等于槽函数参数个数（槽函数接受来自于Qt信号作为参数），PyQt使用自定义参数传递可以解决<span style='background: green'>槽函数参数比信号参数多的问题</span>。使用Lambda表达式或functools的<code>partial</code>函数可以传递自定义参数给槽函数，自定义参数类型可以是Python的任意类型.</p>
<ul>
<li>个人理解：原本通过<code>pyqtSignal</code>定义的信号中参数数量是固定的，他和槽函数一一对应，通过<code>connect</code>函数传递。但是有一些信号，如<code>button.clicked</code>信号就没有参数了，但是有些时候槽函数需要这个信号的相关信息，比如是哪个按钮，这就需要信号传递参数给槽函数。</li>
<li>Lambda表达式或<code>partial</code>函数可以作为无参数或参数比默认的少的函数，可以骗过无参数的信号。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QWidget, QApplication, QPushButton, QHBoxLayout</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainWindow</span>(<span class="params">QWidget</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line">        button1 = QPushButton(<span class="string">&quot;Button1&quot;</span>, self)</span><br><span class="line">        button2 = QPushButton(<span class="string">&quot;Button2&quot;</span>, self)</span><br><span class="line"></span><br><span class="line">        layout = QHBoxLayout()</span><br><span class="line">        layout.addWidget(button1)</span><br><span class="line">        layout.addWidget(button2)</span><br><span class="line">        self.setLayout(layout)</span><br><span class="line"></span><br><span class="line">        self.setWindowTitle(<span class="string">&quot;MainWindow Demo&quot;</span>)</span><br><span class="line">        self.resize(<span class="number">800</span>, <span class="number">600</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        button1.clicked.connect(<span class="keyword">lambda</span>: self.onButtonClick(<span class="number">1</span>))</span><br><span class="line">        button2.clicked.connect(<span class="keyword">lambda</span>: self.onButtonClick(<span class="number">2</span>))</span><br><span class="line">      <span class="comment"># button1.clicked.connect(partial(self.onButtonClick, 1))</span></span><br><span class="line">      <span class="comment"># button2.clicked.connect(partial(self.onButtonClick, 2))</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">onButtonClick</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Button &#123;0&#125; is Clicked&quot;</span>.<span class="built_in">format</span>(n))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    window = MainWindow()</span><br><span class="line">    window.show()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<h3 id="信号槽与装饰器"><a href="#信号槽与装饰器" class="headerlink" title="信号槽与装饰器"></a>信号槽与装饰器</h3><p><a href="https://www.runoob.com/w3cnote/python-func-decorators.html">函数装饰器</a></p>
<p>可以用函数装饰器定义信号槽和槽函数，使用方法如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@PyQt5.QtCore.pyqtSlot(<span class="params"><span class="built_in">bool</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">on_</span>发送者对象名称<span class="title">_</span>发射信号名称(<span class="params">self, parameter</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>使用函数装饰器时，必须用<code>connectSlotsByName(self, QObject)</code>连接槽函数和信号<br><code>QtCore.QMetaObject.connectSlotsByName(self, QObject)</code><br>connectSlotsByName用于将QObject子孙对象的某些信号根据名称连接到某些QObject对象的相应槽函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5 <span class="keyword">import</span> QtCore</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QWidget, QApplication, QPushButton, QHBoxLayout</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainWindow</span>(<span class="params">QWidget</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent = <span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line">        button1 = QPushButton(<span class="string">&quot;Button1&quot;</span>, self)</span><br><span class="line">        button1.setObjectName(<span class="string">&quot;Button1&quot;</span>)</span><br><span class="line">        button2 = QPushButton(<span class="string">&quot;Button2&quot;</span>, self)</span><br><span class="line">        button2.setObjectName(<span class="string">&quot;Button2&quot;</span>)</span><br><span class="line"></span><br><span class="line">        layout = QHBoxLayout()</span><br><span class="line"></span><br><span class="line">        layout.addWidget(button1)</span><br><span class="line">        layout.addWidget(button2)</span><br><span class="line">        self.setLayout(layout)</span><br><span class="line"></span><br><span class="line">        self.setWindowTitle(<span class="string">&quot;MainWindow Demo&quot;</span>)</span><br><span class="line">        self.resize(<span class="number">800</span>, <span class="number">600</span>)</span><br><span class="line"></span><br><span class="line">        QtCore.QMetaObject.connectSlotsByName(self)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @QtCore.pyqtSlot()</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_Button1_clicked</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Button1 is clicked&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @QtCore.pyqtSlot()</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_Button2_clicked</span>(<span class="params">self</span>):</span></span><br><span class="line">        print(<span class="string">&quot;Button2 is clicked&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    window = MainWindow()</span><br><span class="line">    window.show()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<h2 id="事件处理机制"><a href="#事件处理机制" class="headerlink" title="事件处理机制"></a>事件处理机制</h2><h3 id="事件机制与信号槽机制的区别"><a href="#事件机制与信号槽机制的区别" class="headerlink" title="事件机制与信号槽机制的区别"></a>事件机制与信号槽机制的区别</h3><p>PyQt为事件处理提供了高级别的信号槽机制和低级别的事件处理机制，信号槽机制是事件处理机制的高级封装。使用控件时，不用考虑事件处理机制，只需要关心信号槽即可；<span style='background: green'>对于自定义派生控件，必须考虑事件处理机制，根据控件的行为需求重新实现相应的事件处理函数</span></p>
<h3 id="事件处理的方法"><a href="#事件处理的方法" class="headerlink" title="事件处理的方法"></a>事件处理的方法</h3><p>共5种事件处理的方法，分别为：</p>
<ol>
<li>重新实现事件处理函数<br>常用的事件处理函数如<code>paintEvent</code>，<code>mouseMoveEvent</code>、<code>mousePressEvent</code>、<code>mouseReleaseEvent</code>等</li>
<li>重新实现QObject.event事件分发函数<br>在增加新的事件时，需要重新实现QObject.event方法，并增加新事件的<span style='background color=green'>分发路由</span></li>
<li>安装事件过滤器<br>如果对QObject对象调用installEventFilter方法，则为QObject对象安装事件过滤器。QObject对象的所有事件都会先传递到事件过滤器eventFilter函数，在事件过滤器eventFilter函数中可以丢弃或修改某些事件，对感兴趣的事件使用自定义的事件处理机制，对其它事件使用默认事件处理机制。事件过滤机制会对QObject的所有事件进行过滤，因此如果要过滤的事件比较多则会影响程序性能。</li>
<li>在QApplication安装事件过滤器<br>在QApplication对象安装事件过滤器将会对所有QObject对象的所有事件进行过滤，并且会首先获得事件，即将事件发送给其它任何一个事件过滤器前，都会首先发送给QApplication的事件过滤器。</li>
<li>重新QApplication的notify方法<br>PyQt使用QApplication对象的notify方法进行分发事件，要想在任何事件过滤器前捕获事件唯一的方法就是重新实现QApplication的notify方法。</li>
</ol>
<h3 id="事件处理实例"><a href="#事件处理实例" class="headerlink" title="事件处理实例"></a>事件处理实例</h3><blockquote>
<p>QDialog对话框在ESC按键按下时会自动退出，使用事件处理和过滤对按下ESC按键进行处理。</p>
</blockquote>
<ol>
<li>重新实现事件处理函数</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QDialog, QApplication</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtCore <span class="keyword">import</span> Qt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dialog</span>(<span class="params">QDialog</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 重新实现keyPressEvent</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">keyPressEvent</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        <span class="keyword">if</span> event.key() == Qt.Key_Escape:</span><br><span class="line">            QDialog.keyPressEvent(self, event)</span><br><span class="line">            print(event.key())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line"></span><br><span class="line">    dialog = Dialog()</span><br><span class="line">    dialog.show()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<ol>
<li>重新实现event函数</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QDialog, QApplication</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtCore <span class="keyword">import</span> Qt</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtGui <span class="keyword">import</span> QKeyEvent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dialog</span>(<span class="params">QDialog</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 重新实现keyPressEvent</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">event</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        <span class="keyword">if</span> event.<span class="built_in">type</span>() == QKeyEvent.KeyPress <span class="keyword">and</span> event.key() == Qt.Key_Escape:</span><br><span class="line">            <span class="keyword">return</span> QDialog.event(self, event)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    dialog = Dialog()</span><br><span class="line">    dialog.exec_()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<ol>
<li>QObject安装事件过滤器</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QDialog, QApplication</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtCore <span class="keyword">import</span> Qt</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtGui <span class="keyword">import</span> QKeyEvent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dialog</span>(<span class="params">QDialog</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line">        self.installEventFilter(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eventFilter</span>(<span class="params">self, watched, event</span>):</span></span><br><span class="line">        <span class="keyword">if</span> event.<span class="built_in">type</span>() == QKeyEvent.KeyPress <span class="keyword">and</span> event.key() == Qt.Key_Escape:</span><br><span class="line">            <span class="keyword">return</span> QDialog.eventFilter(self, watched, event)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    dialog = Dialog()</span><br><span class="line">    dialog.exec_()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<ol>
<li>QApplication安装事件过滤器</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QDialog, QApplication</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtCore <span class="keyword">import</span> Qt</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtGui <span class="keyword">import</span> QKeyEvent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dialog</span>(<span class="params">QDialog</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(parent)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eventFilter</span>(<span class="params">self, watched, event</span>):</span></span><br><span class="line">        <span class="keyword">if</span> event.<span class="built_in">type</span>() == QKeyEvent.KeyPress <span class="keyword">and</span> event.key() == Qt.Key_Escape:</span><br><span class="line">            <span class="keyword">return</span> QDialog.eventFilter(self, watched, event)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    dialog = Dialog()</span><br><span class="line">    app.installEventFilter(dialog)</span><br><span class="line">    dialog.exec_()</span><br><span class="line"></span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p>参考自:<br><a href="https://blog.51cto.com/u_9291927/2422187">PyQt5快速入门（二）PyQt5信号槽机制</a></p>
]]></content>
      <categories>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title>PyQt5基本窗口控件（一）</title>
    <url>/2021/08/22/Qt-4/</url>
    <content><![CDATA[<h1 id="PyQt5基本窗口控件（一）"><a href="#PyQt5基本窗口控件（一）" class="headerlink" title="PyQt5基本窗口控件（一）"></a>PyQt5基本窗口控件（一）</h1><p>包括 QMainWindow/QWidget/QLabel等三个重要部件<br><span id="more"></span></p>
<h2 id="QMainWindow"><a href="#QMainWindow" class="headerlink" title="QMainWindow"></a>QMainWindow</h2><p>QMainWindow主窗口为用户提供一个应用程序框架，可以在主窗口中添加控件，如工具栏、菜单栏、和状态栏。</p>
<h3 id="窗口类型"><a href="#窗口类型" class="headerlink" title="窗口类型"></a>窗口类型</h3><p><code>QMainwindow</code>, <code>QWidget</code>, <code>QDialog</code>三个类都是用来创建窗口地，但是有区别</p>
<ul>
<li><code>QMainwindow</code>：可以包含菜单栏，工具栏，状态栏，标题栏，是最常见的窗口形式，可以说是主窗口</li>
<li><code>QDialog</code>：是对话框的基类。对话框主要用于执行短期任务，或者与用户进行互动，它可以是模态的，也可以是非模态的，无工具栏状态栏和菜单栏</li>
<li><code>QWidget</code>：可能作为顶层窗口，或者嵌入到其他窗口中。</li>
</ul>
<h3 id="创建主窗口"><a href="#创建主窗口" class="headerlink" title="创建主窗口"></a>创建主窗口</h3><p>父窗口：包含一个或多个窗口，没有父窗口的窗口被称为顶层窗口，<code>QMainWindow</code>就是顶层窗口<br>子窗口：被父窗口包含<br>主窗口不能用<code>setLayout()</code>方法自定义布局，因为他们有自己的布局。</p>
<p><code>QMainwindow</code>继承自<code>QWidget</code>类，其重要的方法包括以下几种</p>
<ul>
<li><code>addToolBar()</code>添加工具栏</li>
<li><code>centralWidget()</code>返回窗口中心的一个控件，未设置时返回NULL</li>
<li><code>menuBar()</code>返回主窗口的菜单栏</li>
<li><code>setCentralWidget()</code>设置窗口中心的控件</li>
<li><code>setStatusBar()</code>设置状态栏</li>
<li><code>statusBar()</code>用于获得状态栏对象，可以对对象调用<code>showMessage(message, int timeout=0)</code>方法显示状态栏信息</li>
</ul>
<p>代码如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QMainWindow, QApplication</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtGui <span class="keyword">import</span> QIcon</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainWindow</span>(<span class="params">QMainWindow</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MainWindow, self).__init__(parent)</span><br><span class="line">        self.resize(<span class="number">400</span>, <span class="number">200</span>)</span><br><span class="line">        self.status = self.statusBar()</span><br><span class="line">        self.status.showMessage(<span class="string">&quot;状态栏提示&quot;</span>, <span class="number">5000</span>)</span><br><span class="line">        self.setWindowTitle(<span class="string">&quot;QMainWindow&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    app.setWindowIcon(QIcon(<span class="string">&quot;1.jpg&quot;</span>))</span><br><span class="line">    form = MainWindow()</span><br><span class="line">    form.show()</span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p><img src="http://fang-bnn.gitee.io/image_bed/bed/PyQt4-1.png" alt="4-1.png"></p>
<h3 id="主窗口居中"><a href="#主窗口居中" class="headerlink" title="主窗口居中"></a>主窗口居中</h3><p><code>QMainwindow.move(int, int)</code>是将窗口的左上角定位至屏幕上的坐标（见下）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QDesktopWidget, QApplication, QMainWindow</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">winform</span>(<span class="params">QMainWindow</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(winform, self).__init__(parent)</span><br><span class="line"></span><br><span class="line">        self.setWindowTitle(<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line">        self.resize(<span class="number">370</span>, <span class="number">250</span>)</span><br><span class="line">        self.center()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">center</span>(<span class="params">self</span>):</span></span><br><span class="line">        screen = QDesktopWidget().screenGeometry()</span><br><span class="line">        size = self.geometry()</span><br><span class="line">        self.move((screen.width() - size.width()) / <span class="number">2</span>, (screen.height() - size.height()) / <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    win = winform()</span><br><span class="line">    win.show()</span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p><code>QDesktopWidget().screenGeometry()</code>返回屏幕大小，<code>.geometry()</code>方法可以获取<code>QMainWindow</code>的大小，并通过<code>.width()</code>和<code>.height()</code>方法获取他们的值</p>
<h3 id="关闭主窗口"><a href="#关闭主窗口" class="headerlink" title="关闭主窗口"></a>关闭主窗口</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QMainWindow, QHBoxLayout, QPushButton, QApplication, QWidget</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WinForm</span>(<span class="params">QMainWindow</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(WinForm, self).__init__(parent)</span><br><span class="line">        self.setWindowTitle(<span class="string">&#x27;close&#x27;</span>)</span><br><span class="line">        self.button1 = QPushButton(<span class="string">&#x27;close&#x27;</span>)</span><br><span class="line">        self.button1.clicked.connect(self.on_button_clicked)</span><br><span class="line"></span><br><span class="line">        layout = QHBoxLayout()</span><br><span class="line">        layout.addWidget(self.button1)</span><br><span class="line"></span><br><span class="line">        main_frame = QWidget()</span><br><span class="line">        main_frame.setLayout(layout)</span><br><span class="line">        self.setCentralWidget(main_frame)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_button_clicked</span>(<span class="params">self</span>):</span></span><br><span class="line">        sender = self.sender()</span><br><span class="line">        print(sender.text()+<span class="string">&#x27; clicked&#x27;</span>)</span><br><span class="line">        qApp = QApplication.instance()</span><br><span class="line">        qApp.quit()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    form = WinForm()</span><br><span class="line">    form.show()</span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p><code>.sender()</code>函数用于获取发送信号的对象，在这里即button1按钮，<code>.text()</code>用于获取按钮的名称。</p>
<h2 id="QWidget-窗口控件"><a href="#QWidget-窗口控件" class="headerlink" title="QWidget(窗口控件)"></a>QWidget(窗口控件)</h2><blockquote>
<p>基础窗口控件QWidget类是所有用户界面对象的基类，所有窗口和控件都直接或间接继承自QWidget类。</p>
<ul>
<li>窗口：没有嵌入到其他控件中的控件称为窗口</li>
<li>控件：按钮、复选框、文本框、表格、进度条<br><img src="http://fang-bnn.gitee.io/image_bed/bed/Qt4-8.png" alt="Qt4-8.png"></li>
</ul>
</blockquote>
<ul>
<li><code>QWidget</code>提供的成员函数：<code>x()</code>,<code>y()</code>获得窗口左上角的坐标，<code>width()</code>,<code>height()</code>获得客户去的宽度和高度。</li>
<li><code>QWidget.geometry()</code>类提供成员函数：<code>x()</code>,<code>y()</code>获得客户去左上角坐标，<code>width()</code>,<code>height()</code>获得客户区的宽度和高度。</li>
<li><code>QWidget.frameGeometry()</code>提供的成员函数：<code>x()</code>,<code>y()</code>获得窗口左上角的坐标，<code>width()</code>,<code>height()</code>获取包含客户区、标题栏和边框在内的<strong>整个窗口的宽度和高度</strong></li>
</ul>
<h3 id="常用的几何结构"><a href="#常用的几何结构" class="headerlink" title="常用的几何结构"></a>常用的几何结构</h3><h4 id="不包含边框"><a href="#不包含边框" class="headerlink" title="不包含边框"></a>不包含边框</h4><ol>
<li>客户区面积<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QWidget.resize(width, height)</span><br><span class="line">QWidget.resiez(QSize)</span><br></pre></td></tr></table></figure>
此时可以用鼠标来调整窗口大小</li>
<li>客户区大小<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QWidget.size()</span><br></pre></td></tr></table></figure></li>
<li>获取客户区域的宽度和高度<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QWiget.width()</span><br><span class="line">QWiget.height()</span><br></pre></td></tr></table></figure></li>
<li>设置客户区的固定宽度和高度<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QWidget.setFixedWidth(<span class="built_in">int</span> width)</span><br><span class="line">QWidget.setFixedHeigth(<span class="built_in">int</span> height)</span><br><span class="line">QWidget.setFiexdSize(Qsize size)</span><br><span class="line">QWidget.setFiexdSize(<span class="built_in">int</span> width, <span class="built_in">int</span> height)</span><br></pre></td></tr></table></figure>
此时不能通过鼠标调整窗口大小。</li>
<li><p>同时改变面积和位置</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QWidget.setGeometry(<span class="built_in">int</span> x, <span class="built_in">int</span> y, <span class="built_in">int</span> width, <span class="built_in">int</span> height);</span><br><span class="line">QWidget.setGeometry(Qrect rect)</span><br></pre></td></tr></table></figure>
<h4 id="包含边框"><a href="#包含边框" class="headerlink" title="包含边框"></a>包含边框</h4></li>
<li><p>获得窗口的大小和位置</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">QWidget.frameGeometry() -&gt; Qrect</span><br></pre></td></tr></table></figure></li>
<li>设置窗口的位置<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QWidget.move(<span class="built_in">int</span> x, <span class="built_in">int</span> y)</span><br><span class="line">QWidget.move(QPoint point)</span><br></pre></td></tr></table></figure></li>
<li>获得窗口左上角的位置<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QWidget.pos()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QWidget, QApplication, QPushButton</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">app = QApplication(sys.argv)</span><br><span class="line">widget = QWidget()</span><br><span class="line">btn = QPushButton(widget)</span><br><span class="line">btn.setText(<span class="string">&quot;Button&quot;</span>)</span><br><span class="line"></span><br><span class="line">btn.move(<span class="number">20</span>, <span class="number">20</span>)</span><br><span class="line">widget.resize(<span class="number">300</span> ,<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">widget.move(<span class="number">250</span>, <span class="number">200</span>)</span><br><span class="line">widget.setWindowTitle(<span class="string">&#x27;PyQt坐标系统例子&#x27;</span>)</span><br><span class="line">widget.show()</span><br><span class="line"></span><br><span class="line">print(widget.x(), widget.y())</span><br><span class="line">print(widget.width(), widget.height())</span><br><span class="line">print(widget.geometry().x(), widget.geometry().y())</span><br><span class="line">sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p>注意这里第一个<code>print</code>返回的是窗口左上角位置，而第二个<code>print</code>返回的是用户区左上角位置。</p>
<h3 id="PyQt5应用"><a href="#PyQt5应用" class="headerlink" title="PyQt5应用"></a>PyQt5应用</h3><p>显示窗口和图标，并且可以修改大小，最大化，最小化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtGui <span class="keyword">import</span> QIcon</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QApplication, QWidget</span><br><span class="line"></span><br><span class="line">app = QApplication(sys.argv)</span><br><span class="line"></span><br><span class="line">window = QWidget()</span><br><span class="line">window.resize(<span class="number">300</span>, <span class="number">200</span>)</span><br><span class="line">window.move(<span class="number">250</span>, <span class="number">250</span>)</span><br><span class="line">window.setWindowTitle(<span class="string">&quot;hello world&quot;</span>)</span><br><span class="line">window.setWindowIcon(QIcon(<span class="string">&quot;./pyramid.svg&quot;</span>))</span><br><span class="line">window.show()</span><br><span class="line"></span><br><span class="line">sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<h3 id="显示气泡信息"><a href="#显示气泡信息" class="headerlink" title="显示气泡信息"></a>显示气泡信息</h3><p><code>QToolTip.setFont(QFont(&#39;SansSerif&#39;, 10))</code>用于设置提示气泡的字体和字号<br><code>self.setToolTip(&#39;This is a &lt;b&gt;tips&lt;/b&gt;&#39;)</code>设置提示语的内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QWidget, QToolTip, QApplication</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtGui <span class="keyword">import</span> QFont</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">win</span>(<span class="params">QWidget</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(win, self).__init__(parent)</span><br><span class="line">        self.initUI()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initUI</span>(<span class="params">self</span>):</span></span><br><span class="line">        QToolTip.setFont(QFont(<span class="string">&#x27;SansSerif&#x27;</span>, <span class="number">10</span>))</span><br><span class="line">        self.setToolTip(<span class="string">&#x27;This is a &lt;b&gt;tips&lt;/b&gt;&#x27;</span>)</span><br><span class="line">        self.setGeometry(<span class="number">200</span>, <span class="number">300</span>, <span class="number">400</span>, <span class="number">400</span>)</span><br><span class="line">        self.setWindowTitle(<span class="string">&#x27;tips demo&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    winf = win()</span><br><span class="line">    winf.show()</span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<h3 id="QLabel"><a href="#QLabel" class="headerlink" title="QLabel"></a>QLabel</h3><p>QLabel一般是一个占位符，可以显示不可编辑的文本、图片、GIF等<br>QLabel继承自QFrame类，而QFrame类继承自QWidget类</p>
<h4 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法,"></a>常用方法,</h4><p><code>setAlignment()</code></p>
<p>按固定值对其文本，<code>Qt.AlignLeft</code>(水平方向靠左对齐)/<code>Qt.AlignRight</code>(水平方向靠右对其)/<code>Qt.AlignCenter</code>(水平方向居中)/<code>Qt.AlignJustify</code>(水平方向调整间距两端对齐)/<code>Qt.AlignTop</code>(垂直方向靠上对齐)/<code>At.AlignBottom</code>(垂直方向靠下对其)/<code>Qt.AlignVCenter</code>(垂直方向居中对齐)</p>
<p><code>setIndent()</code></p>
<p>设置文本缩进值</p>
<p><code>setPixmap()</code>设置QLabel为一个Pixmap图片</p>
<p><code>text()</code></p>
<p>获得QLabel的文本内容</p>
<p><code>setText()</code></p>
<p>设置QLabel的文本内容</p>
<p><code>selectedText()</code></p>
<p>返回选择的文字</p>
<p><code>setBuddy()</code></p>
<p>设置QLabel的助记符以及buddy，这里略</p>
<p><code>setWordWrap()</code></p>
<p>设置是否允许换行</p>
<h4 id="常用信号"><a href="#常用信号" class="headerlink" title="常用信号"></a>常用信号</h4><p><code>linkActivated</code>：当单击标签中嵌入的超链接，希望在新窗口打开这个链接时，<code>setOpenExternalLinks</code>必须设置为<code>true</code><br><code>linkHovered</code>：当鼠标指针划过标签中嵌入的超链接时，需要用槽函数与这个信号绑定</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QMainWindow, QHBoxLayout, QPushButton, QApplication, QWidget</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WinForm</span>(<span class="params">QMainWindow</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(WinForm, self).__init__(parent)</span><br><span class="line">        self.setWindowTitle(<span class="string">&#x27;close&#x27;</span>)</span><br><span class="line">        self.button1 = QPushButton(<span class="string">&#x27;close&#x27;</span>)</span><br><span class="line">        self.button1.clicked.connect(self.on_button_clicked)</span><br><span class="line"></span><br><span class="line">        layout = QHBoxLayout()</span><br><span class="line">        layout.addWidget(self.button1)</span><br><span class="line"></span><br><span class="line">        main_frame = QWidget()</span><br><span class="line">        main_frame.setLayout(layout)</span><br><span class="line">        self.setCentralWidget(main_frame)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_button_clicked</span>(<span class="params">self</span>):</span></span><br><span class="line">        sender = self.sender()</span><br><span class="line">        print(sender.text()+<span class="string">&#x27; clicked&#x27;</span>)</span><br><span class="line">        qApp = QApplication.instance()</span><br><span class="line">        qApp.quit()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    form = WinForm()</span><br><span class="line">    form.show()</span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p>QLabel标签快捷键的使用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QlabelDemo</span>(<span class="params">QDialog</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.setWindowTitle(<span class="string">&quot;QLabelExample&quot;</span>)</span><br><span class="line">        <span class="comment"># 设置标签1的内容，添加快捷键</span></span><br><span class="line">        nameLb1 = QLabel(<span class="string">&#x27;&amp;Name&#x27;</span>, self)</span><br><span class="line">        <span class="comment"># 建立单行文本输入框</span></span><br><span class="line">        nameEd1 = QLineEdit(self)</span><br><span class="line">        <span class="comment"># 标签与文本框绑定，按快捷键Alt+Q可以定位到单行输入框</span></span><br><span class="line">        nameLb1.setBuddy(nameEd1)</span><br><span class="line"></span><br><span class="line">        nameLb2 = QLabel(<span class="string">&#x27;&amp;Password&#x27;</span>, self)</span><br><span class="line">        nameEd2 = QLineEdit(self)</span><br><span class="line">        nameLb2.setBuddy(nameEd2)</span><br><span class="line"></span><br><span class="line">        btnOK = QPushButton(<span class="string">&#x27;&amp;OK&#x27;</span>)</span><br><span class="line">        btnCancel = QPushButton(<span class="string">&#x27;&amp;Cancel&#x27;</span>)</span><br><span class="line">        mainLayout = QGridLayout(self)</span><br><span class="line">        mainLayout.addWidget(nameLb1, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        mainLayout.addWidget(nameEd1, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        mainLayout.addWidget(nameLb2, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        mainLayout.addWidget(nameEd2, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        mainLayout.addWidget(btnOK, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        mainLayout.addWidget(btnCancel, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app = QApplication(sys.argv)</span><br><span class="line">    labelDemo = QlabelDemo()</span><br><span class="line">    labelDemo.show()</span><br><span class="line">    sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p>快捷键的使用，举例说明<br><code>nameLb2 = QLabel(‘&amp;Password’, self)</code><br>“&amp;”后面加的第一个首字母大写，这是我们一会儿用到的快捷键，<br>使用方式是Alt+&amp;后面大写的第一个字母<br>这里正确的使用方式是Alt+P就可以快速定位到所绑定的伙伴控件上，后面的快捷键使用类似.</p>
]]></content>
      <categories>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyQt5</tag>
        <tag>Widgets</tag>
      </tags>
  </entry>
  <entry>
    <title>anchor box</title>
    <url>/2021/09/18/anchor-box/</url>
    <content><![CDATA[<h1 id="Anchor-Box"><a href="#Anchor-Box" class="headerlink" title="Anchor Box"></a>Anchor Box</h1><p> Anchor boxex是学习卷积神经网络用于目标识别过程中最重要且最难理解的一个概念。这个概念最初是在Faster R-CNN中提出，之后在诸多优秀的目标识别中得到验证，本文主要参考自<a href="https://zhuanlan.zhihu.com/p/63024247">锚框: Anchor box综述</a></p>
<span id="more"></span>
<h2 id="为什么需要anchor-box？"><a href="#为什么需要anchor-box？" class="headerlink" title="为什么需要anchor box？"></a>为什么需要anchor box？</h2><p>先前的目标检测方式主要包括<strong>滑动窗口法</strong>和<strong>区域建议法</strong>，滑动窗口法存在窗口尺寸固定，窗口较多，运算量很大的问题；而区域建议法则是R-CNN的核心思想。通过CNN和RPN生成。通过RPN，生成候选区，然后输入到分类网络中得到最终的分类。</p>
<h3 id="Anchor-box"><a href="#Anchor-box" class="headerlink" title="Anchor box"></a>Anchor box</h3><p>因为一个窗口只能检测一个目标，而且难以解决多尺度的问题，所以第二代检测中提出了特征金字塔的方法，对窗口进行不同分辨率尺度下的检测，但是这大大增加了计算量。</p>
<p><img src="https://pic3.zhimg.com/80/v2-bdcdb12acfa1398a907a5e096e634a22_720w.jpg" alt="example">如图，红框中的人和车的中心点都在这个框中，然而按照以前的方法，一个格子能预测一个对象，而且他对于y输出的向量$y=[p_c, b_x, b_y, b_h, b_w, c_1, c_2]^T$，可以检测这三个类别，但是只能二选一，而不能都输出。所以回丢弃一种可能，导致一些对象无法被检测出来。因此引入了anchor box</p>
<p><img src="https://img-blog.csdnimg.cn/2020020823275943.png" alt="anchor box的形状"><br>所以将上述张量重复两次，得到$y=[p_c, b_x, b_y, b_h, b_w, c_1, c_2, p_c, b_x, b_y, b_h, b_w, c_1, c_2]$。行人一般符合AB1的形状，而汽车符合AB2的形状，所以金标准应该是$y=[1, b_x, b_y, b_h, b_w, 1, 0, 1, b_x, b_y, b_h, b_2, 0, 1]$</p>
<h3 id="为什么使用不同尺寸和不同的长宽比"><a href="#为什么使用不同尺寸和不同的长宽比" class="headerlink" title="为什么使用不同尺寸和不同的长宽比"></a>为什么使用不同尺寸和不同的长宽比</h3><p>为了得到较大的交并比<br>因为不同物体的形状是不一样的，车子的形状和人的形状应该使用不同长宽比的anchor box，从而提高IOU，那么如何选择anchor box的尺寸呢</p>
<ul>
<li>人为经验选取</li>
<li>k-means聚类</li>
<li>作为超参数学习</li>
</ul>
<h2 id="Anchor-box在各个阶段的使用"><a href="#Anchor-box在各个阶段的使用" class="headerlink" title="Anchor box在各个阶段的使用"></a>Anchor box在各个阶段的使用</h2><h3 id="标注阶段"><a href="#标注阶段" class="headerlink" title="标注阶段"></a>标注阶段</h3><p>在训练阶段，是把anchor box作为训练样本，为了训练样本我们需要为每个锚框标注两类标签：一是锚框所含目标的类别，简称类别；二是真实边界框相对锚框的偏移量，简称偏移量（offset）<br>在目标检测时，我们首先生成多个锚框，然后为每个锚框预测类别以及偏移量，接着根据预测的偏移量调整锚框位置从而得到预测边界框，最后筛选需要输出的预测边界框。</p>
<p>假设图像中有$n_a$个anchor box，有$n_b$个真实边界框，那么就形成了一个anchor box与真实边界框之间的关系矩阵（一一对应关系）$X \in R^{n_a\times n_b}$，根据这个对应关系找出每个anchor box<strong>交并比</strong>最大的真实边框，然后以真实边框作为anchor box的边框，计算anchor box相对于真实边框的偏移量，如此就标记好了每个anchor box的<strong>标签和偏移量</strong>（<strong>这意味预测得到的anchor box永远无法实现标注的物体边框，而是只能尽量接近标注的物体边框，因为它的金标准也只是anchor box</strong>）</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>在经过卷积和池化之后，在feature map层使用anchor box，经过一系列的特征提取，最后针对$3\times 3$网格会得到一个$3\times3\times2\times8$的特征层，其中2是anchor box的个数，用了2个anchor box， 8代表每个anchor box的8维特征向量，分别是4个位置偏移量（$H, W, X, Y$）和3个类别（one-hot），1个anchor box标注（anchor box与真实边框交并比最大则为1，否则为0）</p>
<p>前向传递得到anchor box之后，找到预先标注的anchor box，然后计算这个anchor box和ground truth之间的损失，训练的主要目的就是训练出用anchor box去拟合真实边框的模型参数.</p>
<ul>
<li>损失函数（Faster R-CNN）</li>
</ul>
<script type="math/tex; mode=display">
L(\{p_i\}, \{t_i\}) =\frac{1}{N_{cls}}\sum_iL_{cls}(p_i, p_i^{*})+\lambda\frac{1}{N_{reg}}\sum_ip_i^*L_{reg}(t_i,t_i^*)</script><p>$L<em>{cls}(p_i, p_i^*)$代表类别损失，$L</em>{reg}(t_i, t_i^*)$代表位置损失，$t_i^*$是真实的边框相对于anchor box4个参数化坐标的向量。</p>
<h3 id="预测阶段"><a href="#预测阶段" class="headerlink" title="预测阶段"></a>预测阶段</h3><p>图像通过前向传递，最终生成多个anchor box，然后根据训练好的模型参数去预测这些anchor box的偏移量和类别，进而得到预测的边框值，由于阈值和anchor box数量选择问题，同一个目标可能会输出多个相似的预测边框，这样不仅不简洁，而且会增加计算量，为了解决这个问题，常常采用非极大值抑制。</p>
<p>我们常用IOU来代表置信度，什么意思呢？如下图，左图中存在三个框，计算这三个框之间的IOU，得出置信度得分。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/NMS.png" alt="NMS"></p>
<p>流程如下</p>
<ol>
<li>根据置信度得分进行排序</li>
<li>选择置信度最高的边框添加到最终输出列表中，将其从边框列表中删除</li>
<li>计算所有边界框的IoU</li>
<li>删除IoU大于阈值的边界框</li>
<li>重复上述过程，直到边界列表为空</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nms</span>(<span class="params">bounding_boxes, confidence_score, threshold</span>):</span></span><br><span class="line">    <span class="comment"># If no bounding boxes, return empty list</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(bounding_boxes) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> [], []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Bounding boxes</span></span><br><span class="line">    boxes = np.array(bounding_boxes)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># coordinates of bounding boxes</span></span><br><span class="line">    start_x = boxes[:, <span class="number">0</span>]</span><br><span class="line">    start_y = boxes[:, <span class="number">1</span>]</span><br><span class="line">    end_x = boxes[:, <span class="number">2</span>]</span><br><span class="line">    end_y = boxes[:, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Confidence scores of bounding boxes</span></span><br><span class="line">    score = np.array(confidence_score)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Picked bounding boxes</span></span><br><span class="line">    picked_boxes = []</span><br><span class="line">    picked_score = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute areas of bounding boxes</span></span><br><span class="line">    areas = (end_x - start_x + <span class="number">1</span>) * (end_y - start_y + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sort by confidence score of bounding boxes</span></span><br><span class="line">    order = np.argsort(score)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Iterate bounding boxes</span></span><br><span class="line">    <span class="keyword">while</span> order.size &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># The index of largest confidence score</span></span><br><span class="line">        index = order[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Pick the bounding box with largest confidence score</span></span><br><span class="line">        picked_boxes.append(bounding_boxes[index])</span><br><span class="line">        picked_score.append(confidence_score[index])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute ordinates of intersection-over-union(IOU)</span></span><br><span class="line">        x1 = np.maximum(start_x[index], start_x[order[:-<span class="number">1</span>]])</span><br><span class="line">        x2 = np.minimum(end_x[index], end_x[order[:-<span class="number">1</span>]])</span><br><span class="line">        y1 = np.maximum(start_y[index], start_y[order[:-<span class="number">1</span>]])</span><br><span class="line">        y2 = np.minimum(end_y[index], end_y[order[:-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute areas of intersection-over-union</span></span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, x2 - x1 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, y2 - y1 + <span class="number">1</span>)</span><br><span class="line">        intersection = w * h</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute the ratio between intersection and union</span></span><br><span class="line">        ratio = intersection / (areas[index] + areas[order[:-<span class="number">1</span>]] - intersection)</span><br><span class="line"></span><br><span class="line">        left = np.where(ratio &lt; threshold)</span><br><span class="line">        order = order[left]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> picked_boxes, picked_score</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Yolo</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>Yolo</tag>
        <tag>Yolox</tag>
      </tags>
  </entry>
  <entry>
    <title>log20210815</title>
    <url>/2021/08/15/log-20210815/</url>
    <content><![CDATA[<h1 id="20210815"><a href="#20210815" class="headerlink" title="20210815"></a>20210815</h1><blockquote>
<p>晚上在deploy的时候出现了新的问题：<code>error spawn failed</code>，尝试多种方法均不成功，最后发现是<code>deploy</code>中的<code>repo</code>出现了问题。<br>另外，在部署的博客中发现点击目录无响应以及目录显示不全的情况，现已修正。<br><span id="more"></span></p>
</blockquote>
<h2 id="部署问题"><a href="#部署问题" class="headerlink" title="部署问题"></a>部署问题</h2><p>把博客根目录下的<code>_config.yml</code>文件中的<code>deploy</code>下的<code>repo</code>更改为即可<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">git@github.com:xxx/xxx.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure></p>
<h2 id="目录问题"><a href="#目录问题" class="headerlink" title="目录问题"></a>目录问题</h2><p>目录出现显示不全和点击不发生跳转问题，现已解决</p>
<h3 id="显示不全"><a href="#显示不全" class="headerlink" title="显示不全"></a>显示不全</h3><p>把<code>next</code>下的<code>_config.yml</code>文件下的<code>toc</code>下的所有选项全部选<code>true</code>，如下，即可<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">toc:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Automatically add list number to toc.</span></span><br><span class="line">  <span class="attr">number:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># If true, all words will placed on next lines if header width longer then sidebar width.</span></span><br><span class="line">  <span class="attr">wrap:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># If true, all level of TOC in a post will be displayed, rather than the activated part of it.</span></span><br><span class="line">  <span class="attr">expand_all:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Maximum heading depth of generated toc.</span></span><br><span class="line">  <span class="attr">max_depth:</span> <span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<h3 id="点击跳转"><a href="#点击跳转" class="headerlink" title="点击跳转"></a>点击跳转</h3><p>参考github上老哥的操作，极其顺利。参考链接如下：</p>
<p><a href="https://github.com/theme-next/hexo-theme-next/pull/1540/commits/ec521c927dc10255977324284c1c667f2e220da7">nexT主题下目录点击跳转</a></p>
]]></content>
      <categories>
        <category>log</category>
      </categories>
      <tags>
        <tag>log</tag>
        <tag>toc</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>声之向往</title>
    <url>/2022/07/17/Sounds/</url>
    <content><![CDATA[<h1 id="声之向往"><a href="#声之向往" class="headerlink" title="声之向往"></a>声之向往</h1><p>音乐大概是四年时间中，除了床之外接触最多的事物。高中时期没有手机，只能在晚自修前的校园广播台，或是趁着教室人少，偷偷（光明正大）地去放教室电脑内的存货。大学后有了手机，便有了听歌自由，听歌就变得愈发猖狂起来，一首全长42:56的《The dark side of the moon》，耳机一带一摘，一节课就过去了。耳机也不知换了几对，从买手机送的，四六级考试买的有线耳机，到朋友送的TWS蓝牙耳机，到真无线耳机，蓝牙音箱。近期Science的一项研究表明，声音能够通过皮质丘脑回路起到镇痛作用<sup>[1]</sup>（虽然是5dB SNR的白噪声）,但这也许是我听歌的原因之一（”<em>Well I can ease your pain, Get you on your feet again</em>“）。</p>
<h2 id="大一-大二秋冬"><a href="#大一-大二秋冬" class="headerlink" title="大一-大二秋冬"></a>大一-大二秋冬</h2><p>受到高中班级“音乐氛围”影响，大一大二时期听歌的曲目主要集中在摇滚和沙雕小情歌。由于个人理解能力有限，我听不懂大多数摇滚，只是觉得那些旋律和节奏充满力量。而这些力量可以很好地表达当时我内心的无端的愤怒，再加上一些隐晦的歌词的联系，可以很好地安抚我内心对现实的不满。主要听的歌手/乐队包括Pink Floyd，“南京市民李先生”，唐朝，Metallica，万青，痛仰等。大一大二的大多数空闲时间都独自在东一五楼的自习室中刷题度过，从微积分ⅠⅡⅢ，线代，普物ⅠⅡ，C小C大，到有机，概统，电原，数电，常微偏微复变。高中养成的古怪嗜好依旧延续到了大学，在刷题中获取快感，就算与专业毫无干系，但是解题结果和答案的一致，PTA中满屏的绿色勾勾总让我感到快乐，甚至上头；但是每次做题卡壳，PTA中那个永远消除不了的叉叉，总让我恼火。这时候，我一般会把耳机开到我生理承受范围的极大值，把自己淹没在鼓点、电吉他的延音、各种迷幻的效果和主唱的嘶吼中。</p>
<p>Metallica的《Fade to Black》和《Nothing Else Matters》总成为我考炸后的安慰。万青开头看似散漫的唱调，但总在歌曲的某些地方迸发出呐喊，“<em>是谁来自山川湖海，却囿于昼夜厨房与爱</em>”，来时充满梦想，有走遍五湖四海的勇气，但终究为生活所困；“于是他默默追逐着，横渡海峡，年轻的人，看着他们，为了彼岸，骄傲地，骄傲的灭亡”，一长串休止符后，在阵阵逐渐密集的鼓点中，为了追求终极而骄傲地燃烧自我，让我联想到刺猬的“<em>生如烟花，炸开自己纵情燃烧吧</em>”。在南京市民李先生还没有下架前，我最常听那些最为人所知的歌曲：《关于郑州的记忆》，《梵高先生》，《这个世界会好吗》，《我们不能失去信仰》，《热河》等，“<em>似是而非或是世事可畏，有情有义又是有米无炊</em>”，我到现在还是没太理解这句话，纯粹觉得好听；“<em>生命曾经闪耀思想的荣光，我们不能，不能失去信仰</em>”，在下架后，找到了一些相关的现场资源，第一次听电声与管弦乐，还是很震撼的。</p>
<p>东一A五楼没有饮水机，我常常去东一B四楼倒水。去倒水时，我常常会在东一B五楼的天台处看天，看鸟，看启真湖，或是在天桥看看远处的<del>雪山</del>灯火。这时候常会听PF的《High Hopes》、《Marooned》，《Wish You Were Here》，《Echoes》等。晚自习结束，骑着单车滑行在空无一人的文广，有时候会遇见轮滑社的同学，如果运气好，文广地面的积水倒映着南方天空的月亮，“<em>珠碎点点清 玉水河塘 鳞鳞月破去 心泉摇晃 今宵对昨夜 明空浩荡 残思追穹方 月已西往…我要抚摸你</em>”，这大概是我听过的最美的歌。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/essay1.png" alt="大一"></p>
<p>而那些思政课程和部分通识课，总让我感到愤怒和不屑，思修，史纲，马原，毛概，我愿称之为“四大jin’gang”（危，就没一门课上3.6的）。学生活动和社会实践，总存在这样或是那样的令人不爽；“<em>不，要相信规矩；不，要相信秩序；不，要相信严肃；不，要相信贵贱；不，要相信尊卑；不，要相信傀儡；不，要相信权威；不，要相信稳定；不，要相信繁荣</em>”，虽然这是一首口号歌，但是就是爽；就和去迪拜的爽一样，就像去西安的爽一样，就像在台上指点江山的爽一样，他们一直在互联网的记忆中。但现在看来，我的这些想法可笑幼稚。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/essay2.png" alt="黑子"></p>
<h2 id="大二春夏·疫情"><a href="#大二春夏·疫情" class="headerlink" title="大二春夏·疫情"></a>大二春夏·疫情</h2><p>大二下，疫情围困在家。我的心态就出现了一点小变化，现在一度怀疑自己当时的状态是抑郁的可能性。而从这段时间开始，大概就是四年的转折，无论是精神还是身体，不能说是一蹶不振吧，只能说是每况愈下。大概从这个时候开始听朴师傅、刺猬乐队和谢天笑。始终围困在家中让我倍感焦虑，每一次返校的机会，我都申请了，但是由于年少无知，被坑蒙拐骗，多次妥协，最终还是伤害了自己，直到暑假才申请成功。那段时间，常常骑着小龟去水库旁转。常听的是《No Fear in My Hear》，这整首歌仿佛都在描述我的困境和奢望。《我去2000年》是朴树的第一张专辑，很难受地看到，专辑中的第一首《New Boys》被滥用到各种奇奇怪怪的地方，被各种奇奇怪怪的甜腻嗓音唱出来。其实我觉得整张专辑的情绪是迷惘和愤怒的。专辑里最常听的是《妈妈，我…》、《活着》和《我去2000年》。“<em>他们是些有轨电车，终日往返工厂和住房，他们关心粮食关心电视，他们无所事事，看到他们我感到很难过，上班下班的植物人流，在菜市场里，人行道上，他们冷漠地走着，妈妈，那里面有你</em>”。在困在家中的时间里，我一日又一日地重复着一样地生活，看到重复的人，做他们做重复的事情，仿佛自己被围困在巨大的迷宫中，兜兜转转，又回到原地（”<em>steps taken forwards but sleepwalking back again</em>“）；最后一句“<em>知道吗，我是金子，我要闪光的</em>”仅仅是在自我安慰罢了，我也是我所谓重复的人中的一个，每日活成一个样子。<br>“<em>隔壁老张对我讲，年轻时我和你一样狂，天不怕，地不怕，大碗喝酒，大块地吃肉；后来摔了跟头，老了，就变得谨小与甚微，就忘了梦想只乞求能够平安地活着</em>”。因为出于对形式主义的厌恶，我对学院的某些政策和要求不屑一顾，但最后搞得自己非常难堪，最后不得不跪着舔着把事情填补完了；坚持自己的想法总是要付出代价，那为何不躺平让别人牵着你的鼻子走呢？或者段位再高一点，见机行事，见风使舵，别人出彩你就喝彩，别人出丑你就跑路，也许没有脑子才是最轻松的活法？最后还是活成了老张。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/essay3.png" alt="疫情"></p>
<h2 id="大三-大四秋冬"><a href="#大三-大四秋冬" class="headerlink" title="大三-大四秋冬"></a>大三-大四秋冬</h2><p>这大概是四年中的至暗时刻，“<em>崭新万物正上升幻灭如明星，我却乌云遮目；崭新万物正上升幻灭如明星，乌云遮目</em>”。别人的大三大四，是渴望从平凡到不平凡，而我却苦苦哀求，希望从不平凡变得平凡。我失去了大一大二时的力量和思想，就想活成普通人，别人卷地像生产队地驴，文章批量生产，而我却奢求活成生产队的猪，至少只需要承受最后一刻被宰杀时的痛苦。有人说杀不死你的，只会让你变得更强大，而我的感受是相反的，痛苦是会消磨、蚕食人的意志的。我几乎不再听摇滚，而是一些软绵绵的没有力量的靡靡之音。但就算乌云再浓厚，总有阳光投射进来，“<em>这是如此不可思议的光芒，照亮了这世界，来自你无尽的爱，照亮我生命，也照亮了我的心</em>”，因为这些光芒，我才能“<em>生生不息</em>”。同时，我又开始作死，给自己报了SRTP，深度科研，一个比赛，又加上毕设，我深深地怀疑自己能否顺利毕业，虽然到后来不得不承认这些都挺水，但在当时看来，简直就是痴人说梦。其实这一段可以写的实在太多了，但是真的不想再回忆那些阳光照不到的黑暗角落，所以就这样吧。</p>
<h2 id="大四春夏"><a href="#大四春夏" class="headerlink" title="大四春夏"></a>大四春夏</h2><p>大四春夏，搬回紫金港，完成了大四秋冬留下的所有烂摊子，顺利毕业，这实在是我应该感恩的事情。3月打完比赛（虽然我也只是打打酱油，主要还是队友C），四月五月完成毕设，六月完成SRTP与深度科研结项，六月中下磕磕绊绊地考完最后两门考试，放在5个月前，这都是我不敢想的事情。这段时间，非常幸运地找到了许巍2015年在北京《此时此刻》演唱会视频，以及后来2019《无尽光芒》演唱。这两次演唱会常常给我带来温暖，伴我度过焦虑、不安和紧张。佛法摇滚，真的充满力量，但又不狂躁。亮子的电吉他，贝贝的键盘，苏格兰老大爷的架子鼓，陈悦的笛子，窦颖的和声。正如在《故乡》这段里听众大声喊出的“牛逼”，真的牛逼。在《空谷幽兰》中吉他的solo与笛声遥相呼应，“<em>慧行坚勇究畅恒无极</em>”。《漫步》： “<em>让他自然地来吧，让他悄然地去吧，就这样微笑的看着自己，漫步在这人生里</em>”；《救赎之旅》：“<em>生生不息，向着灿烂的终极；一直以来，在心中的梦想，是用一生，改变这个世界…我被你的爱拯救</em>”；《灵岩》：“<em>迷惘坚定交织的旅程，远比开始预料的艰难，也更曲折，丰富多彩</em>”，“<em>你恩赐什么样的旅程给我，要用尽一生来感知，为何在经历过后我才觉醒，你对我的爱，无与伦比</em>”。《旅行》：“<em>谁画出这天地，又画下我和你，让我们的世界绚丽多彩</em>”，每次在阳台看到夕阳下的变幻莫测的天空，都会想起这句。《只有爱》：“<em>有些经历，我不愿回头，有些记忆，却永远在心里</em>”，“<em>只有爱，才能让我觉醒，即使有烈火，燃烧我的心</em>”；《无尽光芒》：“<em>愿所有的悲伤，都化作所有喜悦的力量，就像你爱这世界，你无尽的光芒</em>”；《我不猜》这首歌也同样融入了部分弦乐program，“<em>我不猜，也不徘徊，此刻青山，在眼前</em>”。最后一首《夕阳中的城市》，节奏平缓。吃完每次晚饭躺在古籍馆的朝南的沙发上，望着巨大落地窗外，天空中斜射进来的夕阳，在末尾电吉他，键盘，架子鼓的交替solo中睡去，听到尽兴处，还会随手比划比划（字是真的烂）。夕阳和橘黄色的灯光，陪伴我度过写论文、de bug、和复习组胚的时光。<br><img src="http://fang-bnn.gitee.io/image_bed/bed/essay4.png" alt="大四"></p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>毕业了，对别人来说，随便搞搞就能毕业；对我来说能顺利毕业真的不容易。一直想着能写些什么，但想来想去总是不知写些什么。按照惯例，我只会写写流水账，或是阴阳怪气地写些俏皮话。我不想做喷子，也不想做日记本，也不想做编译器。我只想审视自己，奈何读的书实在太少，嘴上也就剩下几句诸如“真的C”，“只能是寄”，“真的帅”之类的语气词。所以拾人牙慧，借助别人的语言，表达一些想法。<br>最后，还是用别人的歌词（刺猬乐队·《勐巴拉娜西》），表达祝福：</p>
<p><em>在幻妙的时间里有望喜和奇遇<br>在嘈杂的城市里有永恒的相遇<br>在有生之年里常相伴有知己<br>在曼妙的年龄享有诚挚的爱情</em></p>
<h2 id="Citation"><a href="#Citation" class="headerlink" title="Citation"></a><strong>Citation</strong></h2><p>[1] Zhou W, Ye C, Wang H, et al. Sound induces analgesia through corticothalamic circuits[J]. Science, 2022, 377(6602): 198-204.</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>log20210820</title>
    <url>/2021/08/20/log-20210820/</url>
    <content><![CDATA[<h1 id="20210820"><a href="#20210820" class="headerlink" title="20210820"></a>20210820</h1><blockquote>
<p>为hexo的nexT主题添加了Latex公式的渲染，庆幸当初选用了nexT主题，网上的参考资料还是颇为丰富的<br><span id="more"></span></p>
</blockquote>
<h2 id="更换Hexo默认渲染引擎"><a href="#更换Hexo默认渲染引擎" class="headerlink" title="更换Hexo默认渲染引擎"></a>更换Hexo默认渲染引擎</h2><p>hexo默认的渲染是hexo-renderer-marked，不支持mathjax，所以更换hexo的渲染引擎为hexo-renderer-kramed引擎，支持mathjax的公式输出</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cnpm uninstall hexo-renderer-marked --save</span><br><span class="line">cnpm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure>
<p>可以用<code>npm</code>，但是<code>cnpm</code>更快</p>
<h3 id="cnpm的安装"><a href="#cnpm的安装" class="headerlink" title="cnpm的安装"></a><code>cnpm</code>的安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>
<p>检查是否安装成功<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cnpm -v</span><br></pre></td></tr></table></figure></p>
<h2 id="激活mathjax"><a href="#激活mathjax" class="headerlink" title="激活mathjax"></a>激活mathjax</h2><p>文件路径为: next主题下的<code>_config.yml</code><br>更改内容</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># MathJax Support</span></span><br><span class="line"><span class="attr">mathjax:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">mhchem:</span> <span class="literal">true</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="修改kramed语法解释"><a href="#修改kramed语法解释" class="headerlink" title="修改kramed语法解释"></a>修改kramed语法解释</h2><p>文件路径为：根文件夹下的<code>node_modules/kramed/lib/rules/inline.js</code><br>修改了<code>escape</code>,<code>strong</code>,<code>em</code>.</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> inline = &#123;</span><br><span class="line">  <span class="built_in">escape</span>: <span class="regexp">/^\\([`*\[\]()#$+\-.!_&gt;])/</span>,</span><br><span class="line">  autolink: <span class="regexp">/^&lt;([^ &gt;]+(@|:\/)[^ &gt;]+)&gt;/</span>,</span><br><span class="line">  url: noop,</span><br><span class="line">  html: <span class="regexp">/^&lt;!--[\s\S]*?--&gt;|^&lt;(\w+(?!:\/|[^\w\s@]*@)\b)*?(?:&quot;[^&quot;]*&quot;|&#x27;[^&#x27;]*&#x27;|[^&#x27;&quot;&gt;])*?&gt;([\s\S]*?)?&lt;\/\1&gt;|^&lt;(\w+(?!:\/|[^\w\s@]*@)\b)(?:&quot;[^&quot;]*&quot;|&#x27;[^&#x27;]*&#x27;|[^&#x27;&quot;&gt;])*?&gt;/</span>,</span><br><span class="line">  link: <span class="regexp">/^!?\[(inside)\]\(href\)/</span>,</span><br><span class="line">  reflink: <span class="regexp">/^!?\[(inside)\]\s*\[([^\]]*)\]/</span>,</span><br><span class="line">  nolink: <span class="regexp">/^!?\[((?:\[[^\]]*\]|[^\[\]])*)\]/</span>,</span><br><span class="line">  reffn: <span class="regexp">/^!?\[\^(inside)\]/</span>,</span><br><span class="line">  strong: <span class="regexp">/^__([\s\S]+?)__(?!_)|^\*\*([\s\S]+?)\*\*(?!\*)/</span>,</span><br><span class="line">  em: <span class="regexp">/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/</span>,</span><br><span class="line">  code: <span class="regexp">/^(`+)\s*([\s\S]*?[^`])\s*\1(?!`)/</span>,</span><br><span class="line">  br: <span class="regexp">/^ &#123;2,&#125;\n(?!\s*$)/</span>,</span><br><span class="line">  del: noop,</span><br><span class="line">  text: <span class="regexp">/^[\s\S]+?(?=[\\&lt;!\[_*`$]| &#123;2,&#125;\n|$)/</span>,</span><br><span class="line">  math: <span class="regexp">/^\$\$\s*([\s\S]*?[^\$])\s*\$\$(?!\$)/</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="markdown文本开头添加语句"><a href="#markdown文本开头添加语句" class="headerlink" title="markdown文本开头添加语句"></a>markdown文本开头添加语句</h3><p>在markdown开头添加</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">mathjax:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p><a href="https://www.jianshu.com/p/24a5abb2be98">参考链接</a></p>
]]></content>
      <categories>
        <category>log</category>
      </categories>
      <tags>
        <tag>log</tag>
        <tag>hexo</tag>
        <tag>latex</tag>
      </tags>
  </entry>
  <entry>
    <title>log20210812</title>
    <url>/2021/08/12/log-20210812/</url>
    <content><![CDATA[<h1 id="20210812"><a href="#20210812" class="headerlink" title="20210812"></a>20210812</h1><blockquote>
<p>本博客于2021年2月25日搭建，但由于琐事（主次不分？LOL），未经经营数月，辗转于本地笔记、Notion、博客园等，最后考虑到长期经营的稳定性等，还是选择自己搭建博客。<br><span id="more"></span></p>
</blockquote>
<p>本次博客搭建更新了以下方面内容：</p>
<ul>
<li>购买域名</li>
<li>优化主题</li>
</ul>
<h2 id="域名购买"><a href="#域名购买" class="headerlink" title="域名购买"></a>域名购买</h2><p>选了阿里云（<a href="https://cn.aliyun.com/">阿里云网址</a>）的域名，直接支付宝登陆。可在域名-解析处进行设置。</p>
<p>设置图片如下(ip用ping获取github.io)：<br><img src="http://fang-bnn.gitee.io/image_bed/bed/Snipaste_2021-08-12_15-36-35.png" alt="阿里云"></p>
<p>随后在github对应仓库下进入Setting-Pages，在custom domain中输入注册的域名（建议不要加www）。点击save（我没有选择强制HTTPS），等待一段时间，进入域名即可定向到github建立的博客。</p>
<h2 id="优化主题"><a href="#优化主题" class="headerlink" title="优化主题"></a>优化主题</h2><p>进入本地博客文件夹，进入文件夹下的themes文件夹，右键，git bash here，输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/levblanc/hexo-theme-aero-dual.git</span><br></pre></td></tr></table></figure>
<p>这里会遇到一个奇怪的小问题：无法进行<code>clone</code>，可能是因为我不小心在复制网址的时候按下了<code>Ctrl+c</code>，导致了未知字符的出现，按下<code>Insert</code>即可。</p>
<p>进入<code>_config.yml</code>文件夹，将<code>themes</code>改成对应的主题文件夹名称，最后执行以下命令<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><br>但我一般不执行<code>hexo clean</code>,若执行，则会使得custom domain的设置失效。</p>
<h2 id="参考网址"><a href="#参考网址" class="headerlink" title="参考网址"></a>参考网址</h2><p>感谢大佬给出的指南，背景图片真是太难搞了。</p>
<p><a href="https://www.jianshu.com/p/9f794db64f42">更换主题</a><br><a href="https://tding.top/archives/42c38b10.html">主题配置</a><br><a href="https://blog.csdn.net/weixin_46106283/article/details/109880961">背景图片</a><br><a href="https://www.wolfdan.cn/Hexo-Next-Gemini%E4%B8%BB%E9%A2%98%E9%80%8F%E6%98%8E%E5%8C%96%E4%BB%A5%E5%8F%8A%E8%83%8C%E6%99%AF%E5%9B%BE%E7%89%87%E7%9A%84%E6%9B%B4%E6%94%B9/">背景透明</a></p>
]]></content>
      <categories>
        <category>log</category>
      </categories>
      <tags>
        <tag>log</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>yolox_env</title>
    <url>/2021/09/17/yolox-env/</url>
    <content><![CDATA[<h1 id="YOLOX环境配置历程"><a href="#YOLOX环境配置历程" class="headerlink" title="YOLOX环境配置历程"></a>YOLOX环境配置历程</h1><p>主要过程参照<a href="https://blog.csdn.net/qq_39056987/article/details/119002910">这篇大佬博客</a>，但是期间遇到了诸多问题，尝试配置并最终解决，呜呼。</p>
<span id="more"></span>
<h2 id="硬件情况"><a href="#硬件情况" class="headerlink" title="硬件情况"></a>硬件情况</h2><ul>
<li>rtx3080</li>
<li>cuda 11.2（nvidia-smi）</li>
<li>nvcc 10.1</li>
</ul>
<p>其中<code>nvcc -V</code>所得的版本是运行时API，而驱动API是11.2的。</p>
<p>于是从创建虚拟环境开始</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n yolox python=3.7</span><br><span class="line">activate yolox</span><br></pre></td></tr></table></figure>
<p>因为服务器git并没有配置好（可能是代理问题？），无法直接<code>git clone</code>到本地，因此从网上下载后解压缩，并且安装必须的包</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">unzip yolo</span><br><span class="line"><span class="built_in">cd</span> YOLOX</span><br><span class="line">pip3 install -U pip</span><br><span class="line">pip3 install -r requirements.txt</span><br><span class="line">pip3 install -v -e</span><br></pre></td></tr></table></figure>
<p>根据上篇博客所言，pytorch版本为1.8可能会出现无法将tensor加载到cuda上的问题，于是卸载pytorch，重装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip uninstall pytorch</span><br><span class="line">conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge</span><br></pre></td></tr></table></figure>
<p>经过检验，<code>cudatoolkit=11.1</code>版本可以满足11.2版本的需求，其实只是差了个补丁。好了，看到跑到这里，我还以为基本结束了，但是问题还很多…</p>
<h3 id="NVIDIA混合精度库"><a href="#NVIDIA混合精度库" class="headerlink" title="NVIDIA混合精度库"></a>NVIDIA混合精度库</h3><p>然后安装nvidia混合精度库apex</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/NVIDIA/apex</span><br><span class="line"><span class="built_in">cd</span> apex</span><br><span class="line">pip3 install -v --disable-pip-version-check --no-cache-dir --global-option=<span class="string">&quot;--cpp_ext&quot;</span> --global-option=<span class="string">&quot;--cuda_ext&quot;</span> ./</span><br></pre></td></tr></table></figure>
<p>第一步其实并没有必要， 因为我下载的包中已经有apex文件夹。</p>
<p>第三步出现问题：</p>
<p><img src="http://fang-bnn.gitee.io/image_bed/bed/image-20210917092612461.png" alt="problem"></p>
<p>这里提到cuda扩展和pytorch的cuda版本不一致，<a href="https://zhuanlan.zhihu.com/p/345833286">查阅后</a>才发现，要和runtime cuda版本一致，即<code>nvcc -V</code>得出的一致，但是更改成10.2版本会导致无法将tensor load到cuda中，因此打算更新cuda</p>
<h3 id="cuda更新"><a href="#cuda更新" class="headerlink" title="cuda更新"></a>cuda更新</h3><p>指路<a href="https://developer.nvidia.com/cuda-11.1.0-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=2004&amp;target_type=runfilelocal">官网</a></p>
<p>按照所给提示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda_11.1.0_455.23.05_linux.run</span><br><span class="line">sudo sh cuda_11.1.0_455.23.05_linux.run</span><br></pre></td></tr></table></figure>
<p>第一步下载比较慢</p>
<p>第二部完成后，进入类图形化界面，选择<code>continue</code>，<code>accept</code>，并且叉掉驱动安装，最后选择<code>install</code>.</p>
<p>完成安装，会在<code>/src/local</code>下发现存在<code>cuda-11.1</code>文件夹</p>
<p>然后编辑bashrc，增加新版本cuda路径</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>增加下面三条</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:/usr/<span class="built_in">local</span>/cuda-11.1/lib64</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/<span class="built_in">local</span>/cuda-11.1/bin</span><br><span class="line"><span class="built_in">export</span> CUDA_HOME=/usr/<span class="built_in">local</span>/cuda-11.1</span><br></pre></td></tr></table></figure>
<p>并且增加环境变量</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/environment</span><br></pre></td></tr></table></figure>
<p>在第一行的最后添加</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">:/usr/<span class="built_in">local</span>/cuda-11.1/bin</span><br></pre></td></tr></table></figure>
<h3 id="重新安装"><a href="#重新安装" class="headerlink" title="重新安装"></a>重新安装</h3><p>重新运行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip3 install -v --disable-pip-version-check --no-cache-dir --global-option=<span class="string">&quot;--cpp_ext&quot;</span> --global-option=<span class="string">&quot;--cuda_ext&quot;</span> ./</span><br></pre></td></tr></table></figure>
<p>出来一大堆信息，掠过，最后安装成功</p>
<h3 id="pycocotools安装"><a href="#pycocotools安装" class="headerlink" title="pycocotools安装"></a>pycocotools安装</h3><p>先安装git</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install git</span><br></pre></td></tr></table></figure>
<p>再安装cython和pycocotools</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip3 install cython; pip3 install <span class="string">&#x27;git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI&#x27;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>log</category>
      </categories>
      <tags>
        <tag>Deep learning</tag>
        <tag>Yolo</tag>
        <tag>Yolox</tag>
        <tag>Environment</tag>
      </tags>
  </entry>
  <entry>
    <title>好的博客笔记</title>
    <url>/2022/02/20/%E5%A5%BD%E7%94%A8%E7%9A%84%E5%8D%9A%E5%AE%A2%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="好的博客和笔记汇总"><a href="#好的博客和笔记汇总" class="headerlink" title="好的博客和笔记汇总"></a>好的博客和笔记汇总</h1><p>日常中看到的好用的笔记和博客汇总帖，感谢各路大神辛苦的码字，才使得我们能够轻松地获得许多原本需要更多精力才能获取的知识。<br><span id="more"></span></p>
<h2 id="深度学习相关"><a href="#深度学习相关" class="headerlink" title="深度学习相关"></a>深度学习相关</h2><ul>
<li><strong>反卷积</strong>：对反卷积Deconvolution的理解，文章从卷积出发讲解反卷积的概念，随后介绍了反卷积的计算，包括能够除尽和不能除尽两种情况。<a href="https://www.cnblogs.com/shine-lee/p/11559825.html">博客地址</a></li>
<li><strong>Binary Cross Entropy</strong>：文章介绍了Binary Cross Entropy，通过简单的可视化例子，比较清楚地讲解了Binary Cross Entropy地原理，随后又简单地介绍了Cross Entroy和 <a href="https://zhuanlan.zhihu.com/p/89391305">博客地址</a></li>
</ul>
<h2 id="Python相关"><a href="#Python相关" class="headerlink" title="Python相关"></a>Python相关</h2><ul>
<li><strong>Python修饰器</strong>：用较简单的例子讲解了修饰器的原理，即参数为函数的函数，并从函数扩展到修饰器类。<a href="https://zhuanlan.zhihu.com/p/51035016">博客地址</a></li>
</ul>
]]></content>
      <categories>
        <category>Daily</category>
      </categories>
      <tags>
        <tag>Daily</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux服务器重装NVIDIA驱动</title>
    <url>/2022/02/06/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%87%8D%E8%A3%85NVIDIA%E9%A9%B1%E5%8A%A8/</url>
    <content><![CDATA[<h1 id="Linux服务器重装NVIDIA驱动"><a href="#Linux服务器重装NVIDIA驱动" class="headerlink" title="Linux服务器重装NVIDIA驱动"></a>Linux服务器重装NVIDIA驱动</h1><p>Ubuntu服务器在某次重启后，NVIDIA驱动失效，在输入<code>nvidia-smi</code>后结果如下：<br><img src="http://fang-bnn.gitee.io/image_bed/bed/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20220205194104.jpg" alt="驱动加载失败"><br>经过兄弟提示，可能是因为Ubuntu重启后发生了更新，使得其与旧的NVIDIA驱动不匹配，因此卸载了旧的NVIDIA驱动，并从官网上下载最新的驱动并安装。<br><span id="more"></span></p>
<h2 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h2><ol>
<li>卸载旧的驱动<br><code>sudo apt-get purge nvidia*</code></li>
<li>查看显卡版本，但是因为<code>nvidia-smi</code>命令已经失效，辛亏有之前的截图<br><img src="http://fang-bnn.gitee.io/image_bed/bed/nividia-smi.png" alt="nvidia-smi"></li>
<li><a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">nvidia官网</a>下载<br><img src="http://fang-bnn.gitee.io/image_bed/bed/nvidia-download.png" alt="nvidia-download"><br>将最新的驱动下载后发送至服务器</li>
</ol>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol>
<li>卸载nouveau服务<br><code>sudo apt-get --purge remove xserver-xorg-video-nouveau</code></li>
<li>确认nouveau服务已经删除<br>输入<code>lsmod | grep nouveau</code>，回车没有输出，则已经删除</li>
<li>安装<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">sudo</span> chmod a+x NVIDIA-Linux-x<span class="number">86</span>_<span class="number">64</span>-<span class="number">510</span>.<span class="number">14</span>.run</span><br><span class="line"><span class="attribute">sudo</span> ./NIVDIA-Linux-x<span class="number">86</span>_<span class="number">64</span>-<span class="number">510</span>.<span class="number">14</span>.run -no-x-check -no-nouveau-check -no-opengl-files</span><br></pre></td></tr></table></figure>
接下来只要无脑按ENTER即可。</li>
<li>用<code>nvidia-smi</code>检验</li>
</ol>
]]></content>
      <categories>
        <category>log</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>驱动</tag>
      </tags>
  </entry>
</search>
